# ============================================================
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================

# rock_paper.py

import cv2
import mediapipe as mp
import numpy as np
import random
import time
import queue
import threading
import os # os ëª¨ë“ˆ ì¶”ê°€
from mediapipe.tasks import python
from mediapipe.tasks.python import vision

# â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼ 1. ìˆ˜ì •ëœ ë¶€ë¶„ (A) â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼
# í´ë˜ìŠ¤ë¡œ ì „ì²´ ë¡œì§ì„ ìº¡ìŠí™”í•˜ì—¬ ëª¨ë¸ ë¡œë”©ì„ í•œ ë²ˆë§Œ ìˆ˜í–‰í•˜ë„ë¡ ë³€ê²½í•©ë‹ˆë‹¤.
class RockPaperGame:
    def __init__(self, command_q: queue.Queue, result_q: queue.Queue, video_frame_q: queue.Queue):
        self.command_q = command_q
        self.result_q = result_q
        self.video_frame_q = video_frame_q
        self.stop_event = threading.Event()

        # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì„¤ì • (ìƒëŒ€ ê²½ë¡œ ë¬¸ì œ í•´ê²°)
        base_dir = os.path.dirname(os.path.abspath(__file__))
        model_path = os.path.join(base_dir, 'gesture_recognizer.task')

        # ì œìŠ¤ì²˜ ì¸ì‹ê¸°(GestureRecognizer) ìƒì„±
        options = vision.GestureRecognizerOptions(
            base_options=python.BaseOptions(model_asset_path=model_path),
            running_mode=vision.RunningMode.IMAGE
        )
        self.recognizer = vision.GestureRecognizer.create_from_options(options)
        print("âœ… ê°€ìœ„ë°”ìœ„ë³´ ì œìŠ¤ì²˜ ëª¨ë¸ ë¯¸ë¦¬ ë¡œë”© ì™„ë£Œ.")

        # ëª¨ë¸ ì˜ˆì—´(Warm-up)ì„ ìœ„í•´ ê°€ì§œ ì´ë¯¸ì§€ë¡œ í•œ ë²ˆ ì‹¤í–‰í•©ë‹ˆë‹¤.
        try:
            print("â–¶ ê°€ìœ„ë°”ìœ„ë³´ ëª¨ë¸ ì˜ˆì—´ ì¤‘...")
            dummy_image = np.zeros((100, 100, 3), dtype=np.uint8)
            dummy_mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=dummy_image)
            self.recognizer.recognize(dummy_mp_image)
            print("âœ… ê°€ìœ„ë°”ìœ„ë³´ ëª¨ë¸ ì˜ˆì—´ ì™„ë£Œ.")
        except Exception as e:
            print(f"âš ï¸ ëª¨ë¸ ì˜ˆì—´ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        # ìµœì†Œ ì¸ì‹ ì ìˆ˜ ë° í•œêµ­ì–´ ë§¤í•‘
        self.MIN_CONFIDENCE_SCORE = 0.7
        self.KOREAN_CHOICES = {"Rock": "ë°”ìœ„", "Paper": "ë³´", "Scissors": "ê°€ìœ„"}

    def _run_game_logic(self):
        """ì‹¤ì œ ê²Œì„ í•œ íŒì„ ì‹¤í–‰í•˜ëŠ” ë¡œì§"""
        print("ğŸ’¡ ê²Œì„ ì‹œì‘ ì‹ í˜¸ ë°›ìŒ. ì œìŠ¤ì²˜ë¥¼ ì¸ì‹í•©ë‹ˆë‹¤.")

        #--- ê²Œì„ ì‹œì‘ ì „ íë¥¼ ë¹„ì›ë‹ˆë‹¤. ---
        while not self.video_frame_q.empty():
            try:
                self.video_frame_q.get_nowait()
            except queue.Empty:
                break


        best_gesture = "None"
        max_confidence_score = 0.0
        recognition_started = False
        start_time = 0
        end_time = time.time() + 20 # ì „ì²´ ì œí•œ ì‹œê°„ 20ì´ˆ

        while time.time() < end_time and not self.stop_event.is_set():
            try:
                frame = self.video_frame_q.get(timeout=0.1)
                mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                recognition_result = self.recognizer.recognize(mp_image)
                
                if recognition_result.gestures:
                    top_gesture = recognition_result.gestures[0][0]
                    gesture_name = top_gesture.category_name
                    confidence_score = top_gesture.score
                    
                    if self.MIN_CONFIDENCE_SCORE <= confidence_score and gesture_name in ["Victory", "Closed_Fist", "Open_Palm"]:
                        if not recognition_started:
                            recognition_started = True
                            start_time = time.time()
                        
                        if confidence_score > max_confidence_score:
                            best_gesture = gesture_name
                            max_confidence_score = confidence_score
                            print(f"[{time.strftime('%H:%M:%S')}] Gesture: {gesture_name}, Score: {confidence_score:.2f}")
                        else:
                            print(f"[{time.strftime('%H:%M:%S')}] Gesture: None")
                                
                if recognition_started and time.time() - start_time >= 3:
                    break
            except queue.Empty:
                continue

        if best_gesture == "None":
            self.result_q.put("ì œìŠ¤ì²˜ë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆì–´ìš”.")
            return

        user_choice_map = {"Victory": "Scissors", "Closed_Fist": "Rock", "Open_Palm": "Paper"}
        user_choice = user_choice_map.get(best_gesture, "")
        computer_choice = random.choice(["Rock", "Paper", "Scissors"])
        
        user_choice_kr = self.KOREAN_CHOICES.get(user_choice, "")
        computer_choice_kr = self.KOREAN_CHOICES.get(computer_choice, "")

        if user_choice == computer_choice:
            result_text = f"ì €ë„ {user_choice_kr}ë¥¼ ëƒˆì–´ìš”. ë¹„ê²¼ë„¤ìš”!"
        elif (user_choice == "Rock" and computer_choice == "Scissors") or \
             (user_choice == "Paper" and computer_choice == "Rock") or \
             (user_choice == "Scissors" and computer_choice == "Paper"):
            print("ì‚¬ìš©ì: " +user_choice)
            result_text = f"ì œê°€ {computer_choice_kr}ë¥¼ ëƒˆë„¤ìš”. ë‹¹ì‹ ì´ ì´ê²¼ì–´ìš”!"
        else:
            print("ì‚¬ìš©ì: " +user_choice)
            result_text = f"ì œê°€ {computer_choice_kr}ë¥¼ ëƒˆì–´ìš”. ì œê°€ ì´ê²¼ë„¤ìš”!"
        
        self.result_q.put(result_text)

    def start_worker(self):
        """ì›Œì»¤ ìŠ¤ë ˆë“œë¥¼ ì‹œì‘í•˜ê³  ëª…ë ¹ì„ ê¸°ë‹¤ë¦½ë‹ˆë‹¤."""
        print("â–¶ ê°€ìœ„ë°”ìœ„ë³´ ì›Œì»¤ ëŒ€ê¸° ì¤‘...")
        while not self.stop_event.is_set():
            try:
                command = self.command_q.get(timeout=1.0)
                if command == "START_GAME":
                    self._run_game_logic()
                elif command == "STOP":
                    break
            except queue.Empty:
                continue
        
        self.recognizer.close()
        print("â–  ê°€ìœ„ë°”ìœ„ë³´ ì›Œì»¤ ì •ìƒ ì¢…ë£Œ")
        
    def stop(self):
        self.stop_event.set()

# ì›Œì»¤ í•¨ìˆ˜ë¥¼ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •
def rock_paper_game_worker(command_q: queue.Queue, result_q: queue.Queue, video_frame_q: queue.Queue):
    game = RockPaperGame(command_q, result_q, video_frame_q)
    game.start_worker()
# â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²