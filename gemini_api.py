# gemini_v2.py
# Windows + Python 3.11.6
# ìŠ¤í˜ì´ìŠ¤ë°” ëˆ„ë¥´ëŠ” ë™ì•ˆ ë…¹ìŒ â†’ ë–¼ë©´ ì „ì‚¬ â†’ Gemini ë‹µë³€ ìƒì„± â†’ ì„ íƒëœ TTSë¡œ ì½ê¸°
# (NEW) í‚¤ì›Œë“œ ì½œë°±: "ì¶¤" â†’ start_dance_cb(), "ê·¸ë§Œ" â†’ stop_dance_cb()
# (NEW) TTS ê·œì¹™: 'ì¶¤'ì´ë©´ ê³ ì • ë©˜íŠ¸ë§Œ ë§í•˜ê¸°, 'ê·¸ë§Œ'ì´ë©´ ë§í•˜ì§€ ì•Šê¸°

import os
import io
import sys
import base64
import queue
import threading
import wave
from dataclasses import dataclass
from datetime import datetime
from typing import Optional, Callable

# --- .env.local ë¡œë“œ ---
try:
    from dotenv import load_dotenv
    if os.path.exists(".env.local"):
        load_dotenv(dotenv_path=".env.local")
    else:
        load_dotenv()
except Exception:
    pass

import numpy as np
import sounddevice as sd
from pynput import keyboard
import google.generativeai as genai
import requests  # <-- Typecast REST

# ---- Windows SAPI COM (ì§ì ‘) ----
import pythoncom
import win32com.client

# ---------------------- ì„¤ì • ----------------------
def _get_env(name: str, default: str | None = None) -> str | None:
    v = os.environ.get(name)
    if v is None or not str(v).strip():
        return default
    return str(v).strip()

def _find_input_device_by_name(name_substr: str) -> int | None:
    """ì…ë ¥ ì¥ì¹˜ ì´ë¦„ 'ë¶€ë¶„ì¼ì¹˜'ë¡œ ì¸ë±ìŠ¤ ì°¾ê¸° (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)"""
    if not name_substr:
        return None
    key = name_substr.lower()
    try:
        for i, d in enumerate(sd.query_devices()):
            if d.get('max_input_channels', 0) > 0 and key in d.get('name', '').lower():
                return i
    except Exception:
        pass
    return None

SAMPLE_RATE = int(_get_env("SAMPLE_RATE", "16000"))
CHANNELS = int(_get_env("CHANNELS", "1"))
DTYPE = _get_env("DTYPE", "int16")

MODEL_NAME = _get_env("MODEL_NAME", "gemini-2.5-flash")

PROMPT_TEXT = (
    "ë‹¤ìŒ ì˜¤ë””ì˜¤ë¥¼ í•œêµ­ì–´ë¡œ ì •í™•íˆ ì „ì‚¬í•´ì¤˜. "
    "ì‚¬ëŒì˜ ëª©ì†Œë¦¬ë¥¼ ì œì™¸í•œ ë‹¤ë¥¸ ì†ŒìŒì€ ë¬´ì‹œí•´ì¤˜. "
    "ì¡ìŒì²˜ëŸ¼ ëŠê»´ì§€ëŠ” ê²ƒë“¤ì€ ë¬´ì‹œí•´ì¤˜."
    "ë¬¸ì¥ë¶€í˜¸ì™€ ë„ì–´ì“°ê¸°ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í•´ì¤˜."
)

SYSTEM_INSTRUCTION = _get_env(
    "SYSTEM_INSTRUCTION",
    "ë„ˆëŠ” ì‚¬ìš©ìì˜ ê°ì •ì„ ë¶„ì„í•˜ê³  ê³µê°í•´ì£¼ëŠ” ì¹œì ˆí•œ ê°ì • ì„œë¹„ìŠ¤ ë¡œë´‡ì´ì•¼. ë„ˆì˜ ì´ë¦„ì€ ëª¨í‹°. ì‚¬ìš©ì ë°œí™”ì— 1~2ë¬¸ì¥ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ë‹µí•´. "
    "ì‚¬ì‹¤ì´ ë¶ˆí™•ì‹¤í•˜ë©´ ì¶”ì¸¡í•˜ì§€ ë§ê³  ì¶”ê°€ ì •ë³´ë¥¼ ìš”ì²­í•´."
)

# --- TTS ì˜µì…˜ (SAPIìš©) ---
TTS_RATE = int(_get_env("TTS_RATE", "0"))          # SAPI: -10..10
TTS_VOLUME = int(_get_env("TTS_VOLUME", "100"))    # SAPI: 0..100
TTS_FORCE_VOICE_ID = _get_env("TTS_FORCE_VOICE_ID", "")
TTS_OUTPUT_DEVICE = _get_env("TTS_OUTPUT_DEVICE", "")  # ì¶œë ¥ ì¥ì¹˜ ì´ë¦„(ì¼ë¶€ í¬í•¨ ë§¤ì¹­)
# --------------------------------------------------


def _extract_text(resp) -> str:
    t = getattr(resp, "text", None)
    if t and str(t).strip():
        return str(t).strip()
    try:
        pieces = []
        for c in getattr(resp, "candidates", []) or []:
            content = getattr(c, "content", None)
            if not content:
                continue
            for p in getattr(content, "parts", []) or []:
                pt = getattr(p, "text", None)
                if pt and str(pt).strip():
                    pieces.append(str(pt).strip())
        if pieces:
            return "\n".join(pieces).strip()
    except Exception:
        pass
    try:
        return str(resp).strip()
    except Exception:
        return ""


@dataclass
class RecorderState:
    recording: bool = False
    frames_q: queue.Queue = queue.Queue()
    stream: sd.InputStream | None = None


class SapiTTSWorker:
    """
    Windows SAPIë¥¼ ì „ìš© ìŠ¤ë ˆë“œì—ì„œ ì§ì ‘ ì‚¬ìš©.
    - ìŒì„±/ì¶œë ¥ ì¥ì¹˜ ì„ íƒ ì§€ì›
    - íì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì½ê³  ì¢…ë£Œ
    """
    def __init__(self):
        self._q: queue.Queue[str | None] = queue.Queue()
        self.voice_id: str | None = None
        self.output_device_desc: str | None = None
        self.ready = threading.Event()
        self.thread = threading.Thread(target=self._run, daemon=False)

    def start(self):
        self.thread.start()
        self.ready.wait(timeout=5)

    def speak(self, text: str):
        if not text:
            return
        print(f"ğŸ”Š TTS enqueue ({len(text)} chars)")
        self._q.put(text)

    def close_and_join(self, drain: bool = True, timeout: float = 15.0):
        try:
            if drain:
                print("â³ TTS ëŒ€ê¸°: í ë¹„ìš°ëŠ” ì¤‘...")
                self._q.join()
            self._q.put(None)
            self.thread.join(timeout=timeout)
        except Exception:
            pass

    def _run(self):
        try:
            pythoncom.CoInitialize()
            voice = win32com.client.Dispatch("SAPI.SpVoice")  # SAPI.SpVoice
            # --- Voice ì„ íƒ ---
            voices = voice.GetVoices()
            chosen_voice_id = None

            if TTS_FORCE_VOICE_ID:
                for i in range(voices.Count):
                    v = voices.Item(i)
                    if v.Id == TTS_FORCE_VOICE_ID:
                        chosen_voice_id = v.Id
                        break
                if not chosen_voice_id:
                    print(f"â„¹ï¸ TTS_FORCE_VOICE_IDë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {TTS_FORCE_VOICE_ID}")

            if not chosen_voice_id:
                # ko/korean/í•œêµ­ì–´ í¬í•¨ ìš°ì„ 
                for i in range(voices.Count):
                    v = voices.Item(i)
                    blob = f"{v.Id} {v.GetDescription()}".lower()
                    if any(t in blob for t in ["ko", "korean", "í•œêµ­ì–´"]):
                        chosen_voice_id = v.Id
                        break
                if not chosen_voice_id and voices.Count > 0:
                    chosen_voice_id = voices.Item(0).Id

            if chosen_voice_id:
                # Set by token
                for i in range(voices.Count):
                    v = voices.Item(i)
                    if v.Id == chosen_voice_id:
                        voice.Voice = v
                        self.voice_id = v.Id
                        break

            # --- ì¶œë ¥ ì¥ì¹˜ ì„ íƒ ---
            outs = voice.GetAudioOutputs()
            chosen_out_desc = None
            if TTS_OUTPUT_DEVICE:
                key = TTS_OUTPUT_DEVICE.lower()
                for i in range(outs.Count):
                    o = outs.Item(i)
                    desc = o.GetDescription()
                    if key in desc.lower():
                        voice.AudioOutput = o
                        chosen_out_desc = desc
                        break
                if not chosen_out_desc:
                    print(f"â„¹ï¸ ì§€ì •í•œ ì¶œë ¥ ì¥ì¹˜ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {TTS_OUTPUT_DEVICE}")

            if not chosen_out_desc and outs.Count > 0:
                try:
                    desc = outs.Item(0).GetDescription()
                except Exception:
                    desc = "System Default"
                chosen_out_desc = desc

            self.output_device_desc = chosen_out_desc

            # --- ì†ë„/ë³¼ë¥¨ ì„¤ì • ---
            try:
                voice.Rate = max(-10, min(10, TTS_RATE))
            except Exception:
                pass
            try:
                voice.Volume = max(0, min(100, TTS_VOLUME))
            except Exception:
                pass

            # ì°¸ê³  ì •ë³´ ì¶œë ¥
            print("ğŸ§ ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ëª©ë¡ (SAPI):")
            for i in range(voices.Count):
                v = voices.Item(i)
                print(f"  - [{i}] id='{v.Id}', desc='{v.GetDescription()}'")
            print("ğŸ”‰ ì‚¬ìš© ê°€ëŠ¥í•œ ì¶œë ¥ ì¥ì¹˜ (SAPI):")
            for i in range(outs.Count):
                o = outs.Item(i)
                print(f"  - [{i}] '{o.GetDescription()}'")
            print(f"â–¶ ì„ íƒëœ ìŒì„± id='{self.voice_id}'")
            print(f"â–¶ ì„ íƒëœ ì¶œë ¥='{self.output_device_desc}'")

            self.ready.set()

            # ì´ˆê¸° í…ŒìŠ¤íŠ¸ í•œ ì¤„
            voice.Speak("ì•ˆë…•í•˜ì„¸ìš”. T T Sê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

            # í ë£¨í”„
            while True:
                item = self._q.get()
                if item is None:
                    self._q.task_done()
                    break
                try:
                    print("ğŸ”ˆ TTS speaking...")
                    # ë™ê¸° ì¬ìƒ
                    voice.Speak(item)
                    print("âœ… TTS done")
                finally:
                    self._q.task_done()

        except Exception as e:
            print(f"â„¹ï¸ TTS ìŠ¤ë ˆë“œ ì˜¤ë¥˜: {e}")
            self.ready.set()
        finally:
            try:
                pythoncom.CoUninitialize()
            except Exception:
                pass


# ======================= Typecast ì „ìš© ì›Œì»¤ =======================
class TypecastTTSWorker:
    """
    Typecast REST APIë¡œ í•©ì„± â†’ WAVë¥¼ ë©”ëª¨ë¦¬ì—ì„œ ì¬ìƒ.
    í•„ìš” env:
      TYPECAST_API_KEY, TYPECAST_VOICE_ID (í•„ìˆ˜)
      TYPECAST_MODEL=ssfm-v21 (ê¸°ë³¸)
      TYPECAST_LANGUAGE=kor   (ê¸°ë³¸)
      TYPECAST_AUDIO_FORMAT=wav (ê¸°ë³¸)
      TYPECAST_EMOTION / TYPECAST_EMOTION_INTENSITY (ì„ íƒ)
      TYPECAST_SEED (ì„ íƒ)
    """
    def __init__(self):
        self._q: queue.Queue[str | None] = queue.Queue()
        self.ready = threading.Event()
        self.thread = threading.Thread(target=self._run, daemon=False)

    def start(self):
        self.thread.start()
        self.ready.wait(timeout=5)

    def speak(self, text: str):
        if text:
            print(f"ğŸ”Š TTS enqueue ({len(text)} chars)")
            self._q.put(text)

    def close_and_join(self, drain: bool = True, timeout: float = 30.0):
        try:
            if drain:
                self._q.join()
            self._q.put(None)
            self.thread.join(timeout=timeout)
        except Exception:
            pass

    def _run(self):
        try:
            api_key = _get_env("TYPECAST_API_KEY")
            voice_id = _get_env("TYPECAST_VOICE_ID")
            if not api_key or not voice_id:
                print("â— TYPECAST_API_KEY ë˜ëŠ” TYPECAST_VOICE_IDê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                self.ready.set()
                return

            model = _get_env("TYPECAST_MODEL", "ssfm-v21")
            language = _get_env("TYPECAST_LANGUAGE", "kor")
            audio_format = _get_env("TYPECAST_AUDIO_FORMAT", "wav")
            emotion = _get_env("TYPECAST_EMOTION", "")
            intensity = float(_get_env("TYPECAST_EMOTION_INTENSITY", "1.0") or "1.0")
            seed_env = _get_env("TYPECAST_SEED", "")
            seed = int(seed_env) if (seed_env and seed_env.isdigit()) else None

            self.ready.set()
            print("â–¶ Typecast TTS ì¤€ë¹„ ì™„ë£Œ")

            url = "https://api.typecast.ai/v1/text-to-speech"
            headers = {"X-API-KEY": api_key, "Content-Type": "application/json"}

            while True:
                item = self._q.get()
                if item is None:
                    self._q.task_done(); break
                try:
                    payload = {
                        "voice_id": voice_id,
                        "text": item,
                        "model": model,
                        "language": language,
                        "output": {
                            "volume": 100,
                            "audio_pitch": 0,
                            "audio_tempo": 1.0,
                            "audio_format": audio_format
                        }
                    }
                    if emotion:
                        payload["prompt"] = {
                            "emotion_preset": emotion,
                            "emotion_intensity": intensity
                        }
                    if seed is not None:
                        payload["seed"] = seed

                    r = requests.post(url, headers=headers, json=payload, timeout=60)
                    if r.status_code == 200:
                        data = r.content  # audio/wav bytes
                        with io.BytesIO(data) as buf:
                            with wave.open(buf, "rb") as wf:
                                sr = wf.getframerate()
                                sampwidth = wf.getsampwidth()
                                frames = wf.readframes(wf.getnframes())
                        # 16-bit PCM ê°€ì •
                        if sampwidth == 2:
                            audio = np.frombuffer(frames, dtype=np.int16).astype(np.float32) / 32768.0
                        else:
                            audio = np.frombuffer(frames, dtype=np.int16).astype(np.float32) / 32768.0
                        sd.play(audio, sr); sd.wait()
                        print("âœ… TTS done")
                    else:
                        print(f"âŒ Typecast ì˜¤ë¥˜ {r.status_code}: {r.text[:200]}")
                finally:
                    self._q.task_done()
        except Exception as e:
            print(f"â„¹ï¸ Typecast TTS ìŠ¤ë ˆë“œ ì˜¤ë¥˜: {e}")
            self.ready.set()


class PressToTalk:
    def __init__(self,
                 start_dance_cb: Optional[Callable[[], None]] = None,
                 stop_dance_cb: Optional[Callable[[], None]] = None):
        api_key = os.environ.get("GOOGLE_API_KEY")
        if not api_key or not api_key.strip():
            print("â— GOOGLE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")
            print("   - .env.local ì˜ˆ: GOOGLE_API_KEY=AIzxxxxxxxxx")
            print("   - ë˜ëŠ” PowerShell: $env:GOOGLE_API_KEY=\"<í‚¤>\" í›„ ì‹¤í–‰")
            sys.exit(1)

        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(MODEL_NAME)
        self.chat = genai.GenerativeModel(
            MODEL_NAME,
            system_instruction=SYSTEM_INSTRUCTION
        ).start_chat(history=[])

        # --- í‚¤ì›Œë“œ ì½œë°± ì €ì¥ ---
        self.start_dance_cb = start_dance_cb
        self.stop_dance_cb  = stop_dance_cb

        # --- TTS ì—”ì§„ ì„ íƒ ---
        engine = _get_env("TTS_ENGINE", "sapi").lower()
        if engine == "typecast":
            self.tts = TypecastTTSWorker()
        else:
            self.tts = SapiTTSWorker()
        self.tts.start()

        self.state = RecorderState()
        self.listener = None
        self._print_intro()

    def _print_intro(self):
        print("\n=== Gemini Press-to-Transcribe + Chat + TTS (Windows, Python 3.11) ===")
        print("â–¶ ìŠ¤í˜ì´ìŠ¤ë°” ëˆ„ë¥´ëŠ” ë™ì•ˆ ë…¹ìŒ â†’ ë–¼ë©´ ì „ì‚¬ + ë‹µë³€ ìƒì„± + ìŒì„± ì¬ìƒ")
        print("â–¶ [User ] ì „ì‚¬ ê²°ê³¼ / [Gemini] ëª¨ë¸ ë‹µë³€")
        print("â–¶ ESC ë¡œ ì¢…ë£Œ (ë‹µë³€ ì½ê¸° ì™„ë£Œ í›„ ì¢…ë£Œ)")
        print("â–¶ í‚¤ì›Œë“œ: 'ì¶¤' â†’ 5ë²ˆ ëª¨í„° ëŒ„ìŠ¤ ì‹œì‘ / 'ê·¸ë§Œ' â†’ ëŒ„ìŠ¤ ì •ì§€Â·ì›ìœ„ì¹˜")
        print(f"â–¶ MODEL={MODEL_NAME}, SR={SAMPLE_RATE}Hz, CH={CHANNELS}, DTYPE={DTYPE}")
        v_id = getattr(self.tts, "voice_id", None)
        out_desc = getattr(self.tts, "output_device_desc", None)
        if v_id:
            print(f"â–¶ TTS Voice : {v_id}")
        if out_desc:
            print(f"â–¶ TTS Output: {out_desc}")
        print("----------------------------------------------------------------\n")

    # ====== ì˜¤ë””ì˜¤ ìº¡ì²˜ ======
    def _audio_callback(self, indata, frames, time_info, status):
        if status:
            print(f"[ì˜¤ë””ì˜¤ ê²½ê³ ] {status}", file=sys.stderr)
        self.state.frames_q.put(indata.copy())

    def _start_recording(self):
        if self.state.recording:
            return
        while not self.state.frames_q.empty():
            try:
                self.state.frames_q.get_nowait()
            except queue.Empty:
                break

        # ----- ì…ë ¥ ì¥ì¹˜ ì„ íƒ: ì¸ë±ìŠ¤ â†’ ì´ë¦„ â†’ ê¸°ë³¸ -----
        device_idx = None
        env_dev = os.environ.get("INPUT_DEVICE_INDEX")
        if env_dev and env_dev.strip():
            try:
                device_idx = int(env_dev.strip())
            except Exception:
                device_idx = None

        if device_idx is None:
            env_name = os.environ.get("INPUT_DEVICE_NAME", "")
            if env_name:
                device_idx = _find_input_device_by_name(env_name)

        # (ì„ íƒ) ì–´ë–¤ ì¥ì¹˜ê°€ ì„ íƒëëŠ”ì§€ ë¡œê·¸
        try:
            if device_idx is not None:
                dinfo = sd.query_devices(device_idx, 'input')
                print(f"ğŸšï¸  ì„ íƒí•œ ì…ë ¥ ì¥ì¹˜: [{device_idx}] {dinfo['name']} | default_sr={dinfo.get('default_samplerate')}")
            else:
                default_in = sd.default.device[0]
                dinfo = sd.query_devices(default_in, 'input')
                print(f"ğŸšï¸  ì‹œìŠ¤í…œ ê¸°ë³¸ ì…ë ¥ ì‚¬ìš©: [{default_in}] {dinfo['name']} | default_sr={dinfo.get('default_samplerate')}")
        except Exception:
            pass

        self.state.stream = sd.InputStream(
            samplerate=SAMPLE_RATE,
            channels=CHANNELS,
            dtype=DTYPE,
            callback=self._audio_callback,
            blocksize=0,
            device=device_idx
        )
        self.state.stream.start()
        self.state.recording = True
        print("ğŸ™ï¸  ë…¹ìŒ ì‹œì‘ (ìŠ¤í˜ì´ìŠ¤ë°” ìœ ì§€ ì¤‘)...")

    def _stop_recording_and_transcribe(self):
        if not self.state.recording:
            return
        print("â¹ï¸  ë…¹ìŒ ì¢…ë£Œ, ì „ì‚¬ ì¤‘...")
        self.state.recording = False

        try:
            if self.state.stream:
                self.state.stream.stop()
                self.state.stream.close()
        finally:
            self.state.stream = None

        chunks = []
        while not self.state.frames_q.empty():
            chunks.append(self.state.frames_q.get())

        if not chunks:
            print("(ë…¹ìŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.)\n")
            return

        audio_np = np.concatenate(chunks, axis=0)
        wav_bytes = self._to_wav_bytes(audio_np, SAMPLE_RATE, CHANNELS, DTYPE)

        threading.Thread(
            target=self._transcribe_then_chat, args=(wav_bytes,), daemon=True
        ).start()

    @staticmethod
    def _to_wav_bytes(audio_np: np.ndarray, samplerate: int, channels: int, dtype: str) -> bytes:
        with io.BytesIO() as buf:
            with wave.open(buf, 'wb') as wf:
                wf.setnchannels(channels)
                wf.setsampwidth(np.dtype(dtype).itemsize)
                wf.setframerate(samplerate)
                wf.writeframes(audio_np.tobytes())
            return buf.getvalue()

    # ----------- ì‚¬ìš©ì í‚¤ì›Œë“œ ì²˜ë¦¬(=TTS ì •ì±… í¬í•¨) -----------
    def _handle_user_keywords(self, text: str) -> str | None:
        """
        ë°˜í™˜ê°’:
          - 'dance' : ì¶¤ ì‹œì‘(ê³ ì • ë©˜íŠ¸ TTS)
          - 'stop'  : ê·¸ë§Œ(ì•„ë¬´ ë§ë„ ì•ˆí•¨)
          - None    : í‚¤ì›Œë“œ ì—†ìŒ
        ìš°ì„ ìˆœìœ„: 'ê·¸ë§Œ' > 'ì¶¤'
        """
        if not text:
            return None
        if "ê·¸ë§Œ" in text:
            print("ğŸ’¡ í‚¤ì›Œë“œ ê°ì§€: 'ê·¸ë§Œ' â†’ DANCE STOP ìš”ì²­")
            if callable(self.stop_dance_cb):
                try: self.stop_dance_cb()
                except Exception as e: print(f"âš ï¸ stop_dance_cb ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            return "stop"
        if "ì¶¤" in text:
            print("ğŸ’¡ í‚¤ì›Œë“œ ê°ì§€: 'ì¶¤' â†’ DANCE START ìš”ì²­")
            if callable(self.start_dance_cb):
                try: self.start_dance_cb()
                except Exception as e: print(f"âš ï¸ start_dance_cb ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            return "dance"
        return None

    def _transcribe_then_chat(self, wav_bytes: bytes):
        """ì˜¤ë””ì˜¤ â†’ ì „ì‚¬ â†’ ëª¨ë¸ ë‹µë³€ ìƒì„± â†’ (ê·œì¹™ì— ë”°ë¼) TTS ì¬ìƒ"""
        try:
            b64 = base64.b64encode(wav_bytes).decode("ascii")
            parts = [
                {"text": PROMPT_TEXT},
                {"inline_data": {"mime_type": "audio/wav", "data": b64}},
            ]
            resp = self.model.generate_content(parts)
            user_text = _extract_text(resp)
            if not user_text:
                print("ğŸ“ ì „ì‚¬ ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.\n")
                return

            ts = datetime.now().strftime("%H:%M:%S")
            print(f"[{ts}] [User ] {user_text}")

            # ì‚¬ìš©ì ë°œí™”ì—ì„œ í‚¤ì›Œë“œ ì²˜ë¦¬ (TTS ì •ì±… í¬í•¨)
            action = self._handle_user_keywords(user_text)

            # ëª¨ë¸ ì‘ë‹µì€ í•­ìƒ ìƒì„±(ë¡œê·¸/ì½˜ì†”ìš©)í•˜ë˜,
            # TTSëŠ” action ê·œì¹™ì— ë”°ë¼ ì„ íƒ/ëŒ€ì²´/ë¬´ìŒ ì²˜ë¦¬
            reply = self.chat.send_message(user_text)
            model_text = _extract_text(reply) or ""
            print(f"[{ts}] [Gemini] {model_text}\n")

            # ====== TTS ê·œì¹™ ======
            if action == "dance":
                # ìƒì„± ì‘ë‹µ ëŒ€ì‹  ê³ ì • ë©˜íŠ¸ë§Œ ë§í•˜ê¸°
                self.tts.speak("ë„¤! ëª¨í‹°ê°€ ì¶¤ì„ ì¶°ë³¼ê²Œìš”")
            elif action == "stop":
                # ì•„ë¬´ ë§ë„ í•˜ì§€ ì•ŠìŒ
                pass
            else:
                # í‰ì†Œì²˜ëŸ¼ ëª¨ë¸ ì‘ë‹µ ë§í•˜ê¸°
                if model_text:
                    self.tts.speak(model_text)

        except Exception as e:
            print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}\n")

    # ----------------- í‚¤ë³´ë“œ í•¸ë“¤ëŸ¬ -----------------
    def _on_press(self, key):
        try:
            if key == keyboard.Key.space:
                self._start_recording()
        except Exception as e:
            print(f"[í‚¤ ì²˜ë¦¬ ì˜¤ë¥˜ on_press] {e}", file=sys.stderr)

    def _on_release(self, key):
        try:
            if key == keyboard.Key.space:
                self._stop_recording_and_transcribe()
            elif key == keyboard.Key.esc:
                print("ì¢…ë£Œí•©ë‹ˆë‹¤. ğŸ‘‹  (ë‹µë³€ ì½ê¸° ì™„ë£Œê¹Œì§€ ì ì‹œë§Œìš”)")
                self.tts.close_and_join(drain=True)
                return False
        except Exception as e:
            print(f"[í‚¤ ì²˜ë¦¬ ì˜¤ë¥˜ on_release] {e}", file=sys.stderr)

    def run(self):
        with keyboard.Listener(on_press=self._on_press, on_release=self._on_release) as self.listener:
            self.listener.join()


if __name__ == "__main__":
    try:
        default_in = sd.default.device[0]
        sr = sd.query_devices(default_in, 'input')['default_samplerate']
        if abs(sr - SAMPLE_RATE) > 1:
            print(f"â„¹ï¸ ì°¸ê³ : ê¸°ë³¸ ì…ë ¥ ì¥ì¹˜ í‘œì¤€ ìƒ˜í”Œë ˆì´íŠ¸={sr:.0f}Hz, ìŠ¤í¬ë¦½íŠ¸={SAMPLE_RATE}Hz")
    except Exception:
        pass

    app = PressToTalk()
    app.run()
