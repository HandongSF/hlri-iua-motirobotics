# gemini_api.py
# Windows/macOS + Python 3.11
# ìŠ¤í˜ì´ìŠ¤ë°” ëˆ„ë¥´ëŠ” ë™ì•ˆ ë…¹ìŒ â†’ ë–¼ë©´ ì „ì‚¬ â†’ Gemini ë‹µë³€ ìƒì„± â†’ ì„ íƒëœ TTSë¡œ ì½ê¸°
# (NEW) í‚¤ì›Œë“œ ì½œë°±: "ì¶¤" â†’ start_dance_cb(), "ê·¸ë§Œ" â†’ stop_dance_cb()
# (NEW) TTS ê·œì¹™: 'ì¶¤'ì´ë©´ ê³ ì • ë©˜íŠ¸ë§Œ ë§í•˜ê¸°, 'ê·¸ë§Œ'ì´ë©´ ë§í•˜ì§€ ì•Šê¸°
# (NEW) ëŸ°ì²˜ ì‹œì‘ ì¸ì‚¬ + ESC ì¢…ë£Œ ì¸ì‚¬
# (NEW) LLM ì˜ë„ ë¼ìš°í„°: ë¶€ì •/ì§ˆë¬¸/ì œì•ˆ ë¬¸ë§¥ì„ êµ¬ë¶„í•´ dance/stop/chat íŒë‹¨
from __future__ import annotations

import os
import io
import sys
import json  # ### NEW: JSON íŒŒì‹±
import base64
import queue
import threading
import wave
import platform
from dataclasses import dataclass
from datetime import datetime
from typing import Optional, Callable

# --- .env.local ë¡œë“œ ---
try:
    from dotenv import load_dotenv
    if os.path.exists(".env.local"):
        load_dotenv(dotenv_path=".env.local")
    else:
        load_dotenv()
except Exception:
    pass

import numpy as np
import sounddevice as sd
from pynput import keyboard
import google.generativeai as genai
import requests  # <-- Typecast REST

IS_WINDOWS = (platform.system() == "Windows")

# ---------------------- ì„¤ì • ----------------------
def _get_env(name: str, default: str | None = None) -> str | None:
    v = os.environ.get(name)
    if v is None or not str(v).strip():
        return default
    return str(v).strip()

def _find_input_device_by_name(name_substr: str) -> int | None:
    """ì…ë ¥ ì¥ì¹˜ ì´ë¦„ 'ë¶€ë¶„ì¼ì¹˜'ë¡œ ì¸ë±ìŠ¤ ì°¾ê¸° (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)"""
    if not name_substr:
        return None
    key = name_substr.lower()
    try:
        for i, d in enumerate(sd.query_devices()):
            if d.get('max_input_channels', 0) > 0 and key in d.get('name', '').lower():
                return i
    except Exception:
        pass
    return None

SAMPLE_RATE = int(_get_env("SAMPLE_RATE", "16000"))
CHANNELS = int(_get_env("CHANNELS", "1"))
DTYPE = _get_env("DTYPE", "int16")

MODEL_NAME = _get_env("MODEL_NAME", "gemini-2.5-flash")

# ### NEW: ì „ì‚¬ í”„ë¡¬í”„íŠ¸ ê°•í™”(ìˆ«ì/ë‚ ì§œ/ì§€ì‹œ êµ¬ë¶„, ì¡ìŒ ë¬´ì‹œ, ê¹”ë”í•œ ë¬¸ì¥)
PROMPT_TEXT = (
    "ë‹¤ìŒì€ ì‚¬ìš©ìì˜ í•œêµ­ì–´ ìŒì„±ì…ë‹ˆë‹¤. ì •í™•í•œ ìµœì¢… ì „ì‚¬ë§Œ ì¶œë ¥í•˜ì„¸ìš”."
    " ê·œì¹™: (1) ì‚¬ëŒ ë°œí™”ë§Œ, (2) ë°°ê²½ìŒ/ì¤‘ì–¼ê±°ë¦¼/ë¹„ì–¸ì–´ìŒì€ ì‚­ì œ,"
    " (3) ì¢…ê²°ì–´ë¯¸Â·ë„ì–´ì“°ê¸°Â·ë¬¸ì¥ë¶€í˜¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ, (4) ê¸°í˜¸ë‚˜ ì² ìê°€ í—·ê°ˆë¦¬ë©´ ì˜ë¯¸ê°€ ëª…í™•í•œ í‘œí˜„ìœ¼ë¡œ,"
    " (5) 'ì¶¤', 'ê·¸ë§Œ' ê°™ì€ ì§€ì‹œì–´ëŠ” ê·¸ëŒ€ë¡œ ë³´ì¡´. ì˜¤ì§ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥."
)

# ### NEW: ê³µê°í˜• ë‹µë³€ ìŠ¤íƒ€ì¼ì„ ë” ëª…í™•íˆ
SYSTEM_INSTRUCTION = _get_env(
    "SYSTEM_INSTRUCTION",
    "ë„ˆëŠ” ê³µê° ì„œë¹„ìŠ¤ ë¡œë´‡ 'ëª¨í‹°'ì•¼. í•œêµ­ì–´ë¡œ 1~2ë¬¸ì¥, ë”°ëœ»í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µí•´."
    " ì‚¬ìš©ìì˜ ì •ì„œ ì‹ í˜¸(í”¼ê³¤, ìŠ¤íŠ¸ë ˆìŠ¤, ë¶ˆì•ˆ)ë¥¼ ë°˜ì˜í•´ ê³µê°í•˜ê³ ,"
    " ì‚¬ì‹¤ì´ ë¶ˆí™•ì‹¤í•˜ë©´ ì§§ê²Œ í™•ì¸ ì§ˆë¬¸ì„ í•´. ê³¼ì¥Â·ê°€ìŠ¤ë¼ì´íŒ… ê¸ˆì§€."
)

# --- TTS ì˜µì…˜ (SAPIìš©) ---
TTS_RATE = int(_get_env("TTS_RATE", "0"))          # SAPI: -10..10
TTS_VOLUME = int(_get_env("TTS_VOLUME", "100"))    # SAPI: 0..100
TTS_FORCE_VOICE_ID = _get_env("TTS_FORCE_VOICE_ID", "")
TTS_OUTPUT_DEVICE = _get_env("TTS_OUTPUT_DEVICE", "")  # ì¶œë ¥ ì¥ì¹˜ ì´ë¦„(ì¼ë¶€ í¬í•¨ ë§¤ì¹­)

# ### NEW: ì‹œì‘/ì¢…ë£Œ ë©˜íŠ¸(í™˜ê²½ë³€ìˆ˜ë¡œ ë³€ê²½ ê°€ëŠ¥)
GREETING_TEXT = _get_env(
    "GREETING_TEXT",
    "ì•ˆë…•í•˜ì„¸ìš”. ì‚¬ìš©ìë‹˜! ì €ëŠ” ë‹¹ì‹ ì˜ ê³µê° ì„œë¹„ìŠ¤ ë¡œë´‡ ëª¨í‹°ì—ìš”! "
    "ì˜¤ëŠ˜ í•˜ë£¨ ë§ì´ í˜ë“œì…¨ì£ ? ì €ì™€ ì´ì•¼ê¸° ë‚˜ëˆ„ê³  ì‹¶ìœ¼ì„¸ìš”?"
)
FAREWELL_TEXT = _get_env(
    "FAREWELL_TEXT",
    "ì¡°ê¸ˆì´ë¼ë„ ë„ì›€ì´ ë˜ì—ˆê¸¸ ë°”ë¼ìš”. ì €ë¥¼ í†µí•´ ì ì‹œ ì‰¬ì—ˆë‹¤ê°€ëŠ” ì‹œê°„ì´ ë˜ì—ˆê¸¸ ë°”ë˜ìš”. ë‹¤ì‹œ í˜ë‚´ì„¸ìš”."
)
ENABLE_GREETING = _get_env("ENABLE_GREETING", "1") not in ("0", "false", "False")

# --------------------------------------------------

def _extract_text(resp) -> str:
    t = getattr(resp, "text", None)
    if t and str(t).strip():
        return str(t).strip()
    try:
        pieces = []
        for c in getattr(resp, "candidates", []) or []:
            content = getattr(c, "content", None)
            if not content:
                continue
            for p in getattr(content, "parts", []) or []:
                pt = getattr(p, "text", None)
                if pt and str(pt).strip():
                    pieces.append(str(pt).strip())
        if pieces:
            return "\n".join(pieces).strip()
    except Exception:
        pass
    try:
        return str(resp).strip()
    except Exception:
        return ""

@dataclass
class RecorderState:
    recording: bool = False
    frames_q: queue.Queue = queue.Queue()
    stream: sd.InputStream | None = None

# ======================= Windows SAPI ì „ìš© ì›Œì»¤ =======================
class SapiTTSWorker:
    """
    Windows SAPIë¥¼ ì „ìš© ìŠ¤ë ˆë“œì—ì„œ ì§ì ‘ ì‚¬ìš©.
    - ìŒì„±/ì¶œë ¥ ì¥ì¹˜ ì„ íƒ ì§€ì›
    - íì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì½ê³  ì¢…ë£Œ
    """
    def __init__(self):
        self._q: queue.Queue[str | None] = queue.Queue()
        self.voice_id: str | None = None
        self.output_device_desc: str | None = None
        self.ready = threading.Event()
        self.thread = threading.Thread(target=self._run, daemon=False)

    def start(self):
        self.thread.start()
        self.ready.wait(timeout=5)

    def speak(self, text: str):
        if not text:
            return
        print(f"ğŸ”Š TTS enqueue ({len(text)} chars)")
        self._q.put(text)

    def close_and_join(self, drain: bool = True, timeout: float = 15.0):
        try:
            if drain:
                print("â³ TTS ëŒ€ê¸°: í ë¹„ìš°ëŠ” ì¤‘...")
                self._q.join()
            self._q.put(None)
            self.thread.join(timeout=timeout)
        except Exception:
            pass

    def _run(self):
        pc = None
        w32 = None
        try:
            if not IS_WINDOWS:
                print("â„¹ï¸ SAPIëŠ” Windows ì „ìš©ì…ë‹ˆë‹¤. (macOSì—ì„œëŠ” ë¹„í™œì„±)")
                self.ready.set()
                return

            import pythoncom as pc
            import win32com.client as w32

            pc.CoInitialize()
            voice = w32.Dispatch("SAPI.SpVoice")

            # --- Voice ì„ íƒ ---
            voices = voice.GetVoices()
            chosen_voice_id = None

            if TTS_FORCE_VOICE_ID:
                for i in range(voices.Count):
                    v = voices.Item(i)
                    if v.Id == TTS_FORCE_VOICE_ID:
                        chosen_voice_id = v.Id
                        break
                if not chosen_voice_id:
                    print(f"â„¹ï¸ TTS_FORCE_VOICE_IDë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {TTS_FORCE_VOICE_ID}")

            if not chosen_voice_id:
                # ko/korean/í•œêµ­ì–´ ìš°ì„ 
                for i in range(voices.Count):
                    v = voices.Item(i)
                    blob = f"{v.Id} {v.GetDescription()}".lower()
                    if any(t in blob for t in ["ko", "korean", "í•œêµ­ì–´"]):
                        chosen_voice_id = v.Id
                        break
                if not chosen_voice_id and voices.Count > 0:
                    chosen_voice_id = voices.Item(0).Id

            if chosen_voice_id:
                for i in range(voices.Count):
                    v = voices.Item(i)
                    if v.Id == chosen_voice_id:
                        voice.Voice = v
                        self.voice_id = v.Id
                        break

            # --- ì¶œë ¥ ì¥ì¹˜ ì„ íƒ ---
            outs = voice.GetAudioOutputs()
            chosen_out_desc = None
            if TTS_OUTPUT_DEVICE:
                key = TTS_OUTPUT_DEVICE.lower()
                for i in range(outs.Count):
                    o = outs.Item(i)
                    desc = o.GetDescription()
                    if key in desc.lower():
                        voice.AudioOutput = o
                        chosen_out_desc = desc
                        break
                if not chosen_out_desc:
                    print(f"â„¹ï¸ ì§€ì •í•œ ì¶œë ¥ ì¥ì¹˜ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {TTS_OUTPUT_DEVICE}")

            if not chosen_out_desc and outs.Count > 0:
                try:
                    desc = outs.Item(0).GetDescription()
                except Exception:
                    desc = "System Default"
                chosen_out_desc = desc

            self.output_device_desc = chosen_out_desc

            # --- ì†ë„/ë³¼ë¥¨ ---
            try:
                voice.Rate = max(-10, min(10, TTS_RATE))
            except Exception:
                pass
            try:
                voice.Volume = max(0, min(100, TTS_VOLUME))
            except Exception:
                pass

            print("ğŸ§ ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ëª©ë¡ (SAPI):")
            for i in range(voices.Count):
                v = voices.Item(i)
                print(f"  - [{i}] id='{v.Id}', desc='{v.GetDescription()}'")
            print("ğŸ”‰ ì‚¬ìš© ê°€ëŠ¥í•œ ì¶œë ¥ ì¥ì¹˜ (SAPI):")
            for i in range(outs.Count):
                o = outs.Item(i)
                print(f"  - [{i}] '{o.GetDescription()}'")
            print(f"â–¶ ì„ íƒëœ ìŒì„± id='{self.voice_id}'")
            print(f"â–¶ ì„ íƒëœ ì¶œë ¥='{self.output_device_desc}'")

            self.ready.set()

            # ì´ˆê¸° í…ŒìŠ¤íŠ¸ í•œ ì¤„
            voice.Speak("ì•ˆë…•í•˜ì„¸ìš”. T T Sê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

            # í ë£¨í”„
            while True:
                item = self._q.get()
                if item is None:
                    self._q.task_done()
                    break
                try:
                    print("ğŸ”ˆ TTS speaking...")
                    voice.Speak(item)  # ë™ê¸°
                    print("âœ… TTS done")
                finally:
                    self._q.task_done()

        except Exception as e:
            print(f"â„¹ï¸ TTS ìŠ¤ë ˆë“œ ì˜¤ë¥˜: {e}")
            self.ready.set()
        finally:
            try:
                if pc is not None:
                    pc.CoUninitialize()
            except Exception:
                pass

# ======================= Typecast ì „ìš© ì›Œì»¤ =======================
class TypecastTTSWorker:
    """
    Typecast REST APIë¡œ í•©ì„± â†’ WAVë¥¼ ë©”ëª¨ë¦¬ì—ì„œ ì¬ìƒ.
    í•„ìš” env:
      TYPECAST_API_KEY, TYPECAST_VOICE_ID (í•„ìˆ˜)
      TYPECAST_MODEL=ssfm-v21 (ê¸°ë³¸)
      TYPECAST_LANGUAGE=kor   (ê¸°ë³¸)
      TYPECAST_AUDIO_FORMAT=wav (ê¸°ë³¸)
      TYPECAST_EMOTION / TYPECAST_EMOTION_INTENSITY (ì„ íƒ)
      TYPECAST_SEED (ì„ íƒ)
    """
    def __init__(self):
        self._q: queue.Queue[str | None] = queue.Queue()
        self.ready = threading.Event()
        self.thread = threading.Thread(target=self._run, daemon=False)

    def start(self):
        self.thread.start()
        self.ready.wait(timeout=5)

    def speak(self, text: str):
        if text:
            print(f"ğŸ”Š TTS enqueue ({len(text)} chars)")
            self._q.put(text)

    def close_and_join(self, drain: bool = True, timeout: float = 30.0):
        try:
            if drain:
                self._q.join()
            self._q.put(None)
            self.thread.join(timeout=timeout)
        except Exception:
            pass

    def _run(self):
        try:
            api_key = _get_env("TYPECAST_API_KEY")
            voice_id = _get_env("TYPECAST_VOICE_ID")
            if not api_key or not voice_id:
                print("â— TYPECAST_API_KEY ë˜ëŠ” TYPECAST_VOICE_IDê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                self.ready.set()
                return

            model = _get_env("TYPECAST_MODEL", "ssfm-v21")
            language = _get_env("TYPECAST_LANGUAGE", "kor")
            audio_format = _get_env("TYPECAST_AUDIO_FORMAT", "wav")
            emotion = _get_env("TYPECAST_EMOTION", "")
            intensity = float(_get_env("TYPECAST_EMOTION_INTENSITY", "1.0") or "1.0")
            seed_env = _get_env("TYPECAST_SEED", "")
            seed = int(seed_env) if (seed_env and seed_env.isdigit()) else None

            self.ready.set()
            print("â–¶ Typecast TTS ì¤€ë¹„ ì™„ë£Œ")

            url = "https://api.typecast.ai/v1/text-to-speech"
            headers = {"X-API-KEY": api_key, "Content-Type": "application/json"}

            while True:
                item = self._q.get()
                if item is None:
                    self._q.task_done(); break
                try:
                    payload = {
                        "voice_id": voice_id,
                        "text": item,
                        "model": model,
                        "language": language,
                        "output": {
                            "volume": 100,
                            "audio_pitch": 0,
                            "audio_tempo": 1.0,
                            "audio_format": audio_format
                        }
                    }
                    if emotion:
                        payload["prompt"] = {
                            "emotion_preset": emotion,
                            "emotion_intensity": intensity
                        }
                    if seed is not None:
                        payload["seed"] = seed

                    r = requests.post(url, headers=headers, json=payload, timeout=60)
                    if r.status_code == 200:
                        data = r.content  # audio/wav bytes
                        with io.BytesIO(data) as buf:
                            with wave.open(buf, "rb") as wf:
                                sr = wf.getframerate()
                                sampwidth = wf.getsampwidth()
                                frames = wf.readframes(wf.getnframes())
                        # 16-bit PCM ê°€ì •
                        if sampwidth == 2:
                            audio = np.frombuffer(frames, dtype=np.int16).astype(np.float32) / 32768.0
                        else:
                            audio = np.frombuffer(frames, dtype=np.int16).astype(np.float32) / 32768.0
                        sd.play(audio, sr); sd.wait()
                        print("âœ… TTS done")
                    else:
                        print(f"âŒ Typecast ì˜¤ë¥˜ {r.status_code}: {r.text[:200]}")
                finally:
                    self._q.task_done()
        except Exception as e:
            print(f"â„¹ï¸ Typecast TTS ìŠ¤ë ˆë“œ ì˜¤ë¥˜: {e}")
            self.ready.set()

# ======================= ë©”ì¸ ì•± =======================
class PressToTalk:
    def __init__(self,
                 start_dance_cb: Optional[Callable[[], None]] = None,
                 stop_dance_cb: Optional[Callable[[], None]] = None,
                 greet_on_start: bool = True):  # ### NEW
        api_key = os.environ.get("GOOGLE_API_KEY")
        if not api_key or not api_key.strip():
            print("â— GOOGLE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")
            print("   - .env.local ì˜ˆ: GOOGLE_API_KEY=AIzxxxxxxxxx")
            print("   - ë˜ëŠ” PowerShell: $env:GOOGLE_API_KEY=\"<í‚¤>\" í›„ ì‹¤í–‰")
            sys.exit(1)

        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(MODEL_NAME)

        # ëŒ€í™”ìš©(ê³µê°)
        self.chat = genai.GenerativeModel(
            MODEL_NAME,
            system_instruction=SYSTEM_INSTRUCTION
        ).start_chat(history=[])

        # ### NEW: ì˜ë„ ë¼ìš°í„°(ì—„ê²© JSON)
        self.router_model = genai.GenerativeModel(
            MODEL_NAME,
            system_instruction=(
                "ë„ˆëŠ” ëª…ë ¹ ë¼ìš°í„°ë‹¤. í•œêµ­ì–´ ë¬¸ì¥ì„ ë³´ê³  ì˜ë„ë¥¼ ë¶„ë¥˜í•œë‹¤. "
                "dance=ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ì¶¤ì„ 'ì‹œì‘í•˜ë¼ê³ ' ëª…ë ¹/ìš”ì²­/ìŠ¹ì¸. "
                "stop=ì¶¤ì„ 'ë©ˆì¶”ë¼'ëŠ” ëª…ë ¹/ìš”ì²­/ìŠ¹ì¸. "
                "chat=ì¼ë°˜ ëŒ€í™”(ì§ˆë¬¸/ì¡ë‹´/ì„¤ëª…/ê°ì •í‘œí˜„/ì¶¤ì— ëŒ€í•œ ê²¬í•´Â·ê°€ì •ì  ì§ˆë¬¸ í¬í•¨). "
                "ë¶€ì •/ê¸ˆì§€/ê±°ì ˆ í‘œí˜„(ì˜ˆ:'ì¶¤ ì¶”ì§€ ë§ˆ','ì¶¤ì€ ì•ˆë¼','ê·¸ë§Œë‘ì§€ ë§ê³  ê³„ì†')ì€ ì •í™•íˆ ë°˜ì˜í•˜ë¼. "
                "ì˜¤ì§ ì•„ë˜ JSONë§Œ ì¶œë ¥:\n"
                '{ "intent": "dance|stop|chat", "normalized_text": "<ì˜ë¯¸ë§Œ ë³´ì¡´í•œ ê°„ê²°í•œ ë¬¸ì¥>", '
                '"speakable_reply": "<ì˜ë„ê°€ chatì¼ ë•Œ 1~2ë¬¸ì¥ ê³µê°í˜• ì§§ì€ ë‹µë³€. dance/stopì´ë©´ ë¹ˆ ë¬¸ìì—´>" }'
            ),
            generation_config={
                "response_mime_type": "application/json",
                "temperature": 0.2
            }
        )

        # --- í‚¤ì›Œë“œ ì½œë°± ì €ì¥ ---
        self.start_dance_cb = start_dance_cb
        self.stop_dance_cb  = stop_dance_cb

        # --- TTS ì—”ì§„ ì„ íƒ ---
        default_engine = "sapi" if IS_WINDOWS else "typecast"
        engine = _get_env("TTS_ENGINE", default_engine).lower()
        if engine == "sapi" and not IS_WINDOWS:
            print("â„¹ï¸ macOSì—ì„œëŠ” SAPIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ Typecastë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            engine = "typecast"

        if engine == "typecast":
            self.tts = TypecastTTSWorker()
        else:
            self.tts = SapiTTSWorker()
        self.tts.start()

        self.state = RecorderState()
        self.listener = None
        self._print_intro()

        # ### NEW: ì‹œì‘ ì¸ì‚¬(ëŸ°ì²˜ ì‹¤í–‰ ì‹œ)
        if greet_on_start and ENABLE_GREETING:
            self.tts.speak(GREETING_TEXT)

    def _print_intro(self):
        print("\n=== Gemini Press-to-Transcribe + Chat + TTS (Windows/macOS) ===")
        print("â–¶ ìŠ¤í˜ì´ìŠ¤ë°” ëˆ„ë¥´ëŠ” ë™ì•ˆ ë…¹ìŒ â†’ ë–¼ë©´ ì „ì‚¬ + ë‹µë³€ ìƒì„± + ìŒì„± ì¬ìƒ")
        print("â–¶ [User ] ì „ì‚¬ ê²°ê³¼ / [Gemini] ëª¨ë¸ ë‹µë³€")
        print("â–¶ ESC ë¡œ ì¢…ë£Œ (ì¢…ë£Œ ë©˜íŠ¸ ì¬ìƒ í›„ ì¢…ë£Œ)")
        print("â–¶ í‚¤ì›Œë“œ: 'ì¶¤' â†’ 5ë²ˆ ëª¨í„° ëŒ„ìŠ¤ ì‹œì‘ / 'ê·¸ë§Œ' â†’ ëŒ„ìŠ¤ ì •ì§€Â·ì›ìœ„ì¹˜")
        print(f"â–¶ MODEL={MODEL_NAME}, SR={SAMPLE_RATE}Hz, CH={CHANNELS}, DTYPE={DTYPE}")
        v_id = getattr(self.tts, "voice_id", None)
        out_desc = getattr(self.tts, "output_device_desc", None)
        if v_id:
            print(f"â–¶ TTS Voice : {v_id}")
        if out_desc:
            print(f"â–¶ TTS Output: {out_desc}")
        print("----------------------------------------------------------------\n")

    # ====== ì˜¤ë””ì˜¤ ìº¡ì²˜ ======
    def _audio_callback(self, indata, frames, time_info, status):
        if status:
            print(f"[ì˜¤ë””ì˜¤ ê²½ê³ ] {status}", file=sys.stderr)
        self.state.frames_q.put(indata.copy())

    def _start_recording(self):
        if self.state.recording:
            return
        while not self.state.frames_q.empty():
            try:
                self.state.frames_q.get_nowait()
            except queue.Empty:
                break

        # ----- ì…ë ¥ ì¥ì¹˜ ì„ íƒ: ì¸ë±ìŠ¤ â†’ ì´ë¦„ â†’ ê¸°ë³¸ -----
        device_idx = None
        env_dev = os.environ.get("INPUT_DEVICE_INDEX")
        if env_dev and env_dev.strip():
            try:
                device_idx = int(env_dev.strip())
            except Exception:
                device_idx = None

        if device_idx is None:
            env_name = os.environ.get("INPUT_DEVICE_NAME", "")
            if env_name:
                device_idx = _find_input_device_by_name(env_name)

        # (ì„ íƒ) ì–´ë–¤ ì¥ì¹˜ê°€ ì„ íƒëëŠ”ì§€ ë¡œê·¸
        try:
            if device_idx is not None:
                dinfo = sd.query_devices(device_idx, 'input')
                print(f"ğŸšï¸  ì„ íƒí•œ ì…ë ¥ ì¥ì¹˜: [{device_idx}] {dinfo['name']} | default_sr={dinfo.get('default_samplerate')}")
            else:
                default_in = sd.default.device[0]
                dinfo = sd.query_devices(default_in, 'input')
                print(f"ğŸšï¸  ì‹œìŠ¤í…œ ê¸°ë³¸ ì…ë ¥ ì‚¬ìš©: [{default_in}] {dinfo['name']} | default_sr={dinfo.get('default_samplerate')}")
        except Exception:
            pass

        self.state.stream = sd.InputStream(
            samplerate=SAMPLE_RATE,
            channels=CHANNELS,
            dtype=DTYPE,
            callback=self._audio_callback,
            blocksize=0,
            device=device_idx
        )
        self.state.stream.start()
        self.state.recording = True
        print("ğŸ™ï¸  ë…¹ìŒ ì‹œì‘ (ìŠ¤í˜ì´ìŠ¤ë°” ìœ ì§€ ì¤‘)...")

    def _stop_recording_and_transcribe(self):
        if not self.state.recording:
            return
        print("â¹ï¸  ë…¹ìŒ ì¢…ë£Œ, ì „ì‚¬ ì¤‘...")
        self.state.recording = False

        try:
            if self.state.stream:
                self.state.stream.stop()
                self.state.stream.close()
        finally:
            self.state.stream = None

        chunks = []
        while not self.state.frames_q.empty():
            chunks.append(self.state.frames_q.get())

        if not chunks:
            print("(ë…¹ìŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.)\n")
            return

        audio_np = np.concatenate(chunks, axis=0)
        wav_bytes = self._to_wav_bytes(audio_np, SAMPLE_RATE, CHANNELS, DTYPE)

        threading.Thread(
            target=self._transcribe_then_chat, args=(wav_bytes,), daemon=True
        ).start()

    @staticmethod
    def _to_wav_bytes(audio_np: np.ndarray, samplerate: int, channels: int, dtype: str) -> bytes:
        with io.BytesIO() as buf:
            with wave.open(buf, 'wb') as wf:
                wf.setnchannels(channels)
                wf.setsampwidth(np.dtype(dtype).itemsize)
                wf.setframerate(samplerate)
                wf.writeframes(audio_np.tobytes())
            return buf.getvalue()

    # ----------- LLM ì˜ë„ ë¼ìš°íŒ… -----------  ### NEW
    def _route_intent(self, text: str) -> dict:
        """
        ë°˜í™˜ ì˜ˆ:
        { "intent":"dance|stop|chat", "normalized_text":"...", "speakable_reply":"..." }
        ì‹¤íŒ¨ ì‹œ chat ê¸°ë³¸ê°’ìœ¼ë¡œ í´ë°±.
        """
        try:
            resp = self.router_model.generate_content(text)
            raw = _extract_text(resp)
            data = json.loads(raw)
            if not isinstance(data, dict):
                raise ValueError("router JSON is not a dict")
            intent = data.get("intent", "chat")
            if intent not in ("dance", "stop", "chat"):
                intent = "chat"
            return {
                "intent": intent,
                "normalized_text": str(data.get("normalized_text", text)),
                "speakable_reply": str(data.get("speakable_reply", "")) if intent == "chat" else ""
            }
        except Exception as e:
            # í´ë°±: ë‹¨ìˆœ ê·œì¹™
            print(f"(router í´ë°±) {e}")
            low = text.lower()
            if any(neg in text for neg in ["í•˜ì§€ ë§ˆ", "í•˜ì§€ë§ˆ", "ì•ˆë¼", "ì•ˆ ë¼", "ê·¸ë§Œë‘ì§€ ë§ˆ", "ë©ˆì¶”ì§€ ë§ˆ"]):
                return {"intent": "chat", "normalized_text": text, "speakable_reply": ""}
            if "ê·¸ë§Œ" in text:
                return {"intent": "stop", "normalized_text": text, "speakable_reply": ""}
            if "ì¶¤" in text:
                return {"intent": "dance", "normalized_text": text, "speakable_reply": ""}
            return {"intent": "chat", "normalized_text": text, "speakable_reply": ""}

    def _transcribe_then_chat(self, wav_bytes: bytes):
        """ì˜¤ë””ì˜¤ â†’ ì „ì‚¬ â†’ (ì˜ë„ ë¼ìš°íŒ…) â†’ ëª¨ë¸ ë‹µë³€ ìƒì„± â†’ (ê·œì¹™ì— ë”°ë¼) TTS ì¬ìƒ"""
        try:
            b64 = base64.b64encode(wav_bytes).decode("ascii")
            parts = [
                {"text": PROMPT_TEXT},
                {"inline_data": {"mime_type": "audio/wav", "data": b64}},
            ]
            resp = self.model.generate_content(parts)
            user_text = _extract_text(resp)
            if not user_text:
                print("ğŸ“ ì „ì‚¬ ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.\n")
                return

            ts = datetime.now().strftime("%H:%M:%S")
            print(f"[{ts}] [User ] {user_text}")

            # ### NEW: LLM ì˜ë„ íŒë³„
            route = self._route_intent(user_text)
            intent = route["intent"]

            # (ë¡œê·¸ìš©) ëŒ€í™” ìƒì„±ì€ í•­ìƒ í•´ë‘ë˜, TTSëŠ” ê·œì¹™ì— ë”°ë¼ ì„ íƒ
            model_text = ""
            speak_text = ""

            if intent == "chat":
                # ì‚¬ìš©ìê°€ ë§í•œ ì˜ë¯¸ë¥¼ ë°˜ì˜í•´ ê³µê°í˜• ë‹µë³€
                # ìš°ì„  ë¼ìš°í„°ê°€ ë§Œë“  ì§§ì€ ë‹µë³€ì„ ì‚¬ìš©, ì—†ìœ¼ë©´ chat ëª¨ë¸ë¡œ ìƒì„±
                if route.get("speakable_reply"):
                    model_text = route["speakable_reply"]
                else:
                    reply = self.chat.send_message(user_text)
                    model_text = _extract_text(reply) or ""
                speak_text = model_text

            elif intent == "dance":
                # ì½œë°± ì‹¤í–‰ + ê³ ì • ë©˜íŠ¸ë§Œ ë§í•˜ê¸°
                print("ğŸ’¡ ì˜ë„: DANCE START")
                if callable(self.start_dance_cb):
                    try: self.start_dance_cb()
                    except Exception as e: print(f"âš ï¸ start_dance_cb ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                model_text = "ë„¤! ëª¨í‹°ê°€ ì¶¤ì„ ì¶°ë³¼ê²Œìš”"
                speak_text = "ë„¤! ëª¨í‹°ê°€ ì¶¤ì„ ì¶°ë³¼ê²Œìš”"

            elif intent == "stop":
                # ì½œë°± ì‹¤í–‰ + ì•„ë¬´ ë§ë„ í•˜ì§€ ì•Šê¸°
                print("ğŸ’¡ ì˜ë„: DANCE STOP")
                if callable(self.stop_dance_cb):
                    try: self.stop_dance_cb()
                    except Exception as e: print(f"âš ï¸ stop_dance_cb ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                model_text = "(ì¶¤ ì •ì§€ ëª…ë ¹ ì²˜ë¦¬)"

            print(f"[{ts}] [Gemini] {model_text}\n")

            # ====== TTS ì¬ìƒ ======
            if speak_text:
                self.tts.speak(speak_text)

        except Exception as e:
            print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}\n")

    # ----------------- í‚¤ë³´ë“œ í•¸ë“¤ëŸ¬ -----------------
    def _on_press(self, key):
        try:
            if key == keyboard.Key.space:
                self._start_recording()
        except Exception as e:
            print(f"[í‚¤ ì²˜ë¦¬ ì˜¤ë¥˜ on_press] {e}", file=sys.stderr)

    def _on_release(self, key):
        try:
            if key == keyboard.Key.space:
                self._stop_recording_and_transcribe()
            elif key == keyboard.Key.esc:
                # ### NEW: ì¢…ë£Œ ë©˜íŠ¸ í›„ ì•ˆì „ ì¢…ë£Œ
                print("ì¢…ë£Œí•©ë‹ˆë‹¤. ğŸ‘‹  (ì¢…ë£Œ ë©˜íŠ¸ ì¬ìƒ í›„ ì¢…ë£Œ)")
                try:
                    if FAREWELL_TEXT:
                        self.tts.speak(FAREWELL_TEXT)
                finally:
                    self.tts.close_and_join(drain=True)
                return False
        except Exception as e:
            print(f"[í‚¤ ì²˜ë¦¬ ì˜¤ë¥˜ on_release] {e}", file=sys.stderr)

    def run(self):
        with keyboard.Listener(on_press=self._on_press, on_release=self._on_release) as self.listener:
            self.listener.join()

# ======================= ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ =======================
if __name__ == "__main__":
    try:
        default_in = sd.default.device[0]
        sr = sd.query_devices(default_in, 'input')['default_samplerate']
        if abs(sr - SAMPLE_RATE) > 1:
            print(f"â„¹ï¸ ì°¸ê³ : ê¸°ë³¸ ì…ë ¥ ì¥ì¹˜ í‘œì¤€ ìƒ˜í”Œë ˆì´íŠ¸={sr:.0f}Hz, ìŠ¤í¬ë¦½íŠ¸={SAMPLE_RATE}Hz")
    except Exception:
        pass

    # ### NEW: ëŸ°ì²˜ ì‹¤í–‰ ì‹œ ì‹œì‘ ì¸ì‚¬ í™œì„±í™”
    app = PressToTalk(greet_on_start=True)
    app.run()
