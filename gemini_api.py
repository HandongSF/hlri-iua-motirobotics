# gemini_api.py

from __future__ import annotations

import os
import io
import sys
import json
import base64
import queue
import threading
import wave
import platform
import random
import time
from dataclasses import dataclass
from datetime import datetime
from typing import Optional, Callable
import multiprocessing
from functools import wraps

try:
    from dotenv import load_dotenv
    if os.path.exists(".env.local"):
        load_dotenv(dotenv_path=".env.local")
    else:
        load_dotenv()
except Exception:
    pass

import numpy as np
import sounddevice as sd
from pynput import keyboard
import google.generativeai as genai
import requests

IS_WINDOWS = (platform.system() == "Windows")

def _get_env(name: str, default: str | None = None) -> str | None:
    v = os.environ.get(name)
    if v is None or not str(v).strip():
        return default
    return str(v).strip()

def _find_input_device_by_name(name_substr: str) -> int | None:
    if not name_substr: return None
    key = name_substr.lower()
    try:
        for i, d in enumerate(sd.query_devices()):
            if d.get('max_input_channels', 0) > 0 and key in d.get('name', '').lower():
                return i
    except Exception:
        pass
    return None

def keep_awake(func: Callable):
    @wraps(func)
    def wrapper(self: 'PressToTalk', *args, **kwargs):
        stop_keep_alive = threading.Event()
        keep_alive_thread = None

        def keep_alive_worker():
            while not stop_keep_alive.wait(timeout=5.0):
                if self.emotion_queue:
                    self.emotion_queue.put("RESET_SLEEPY_TIMER")

        if self.emotion_queue:
            keep_alive_thread = threading.Thread(target=keep_alive_worker, daemon=True)
            keep_alive_thread.start()

        try:
            return func(self, *args, **kwargs)
        finally:
            if keep_alive_thread:
                stop_keep_alive.set()
            if self.emotion_queue:
                self.emotion_queue.put("RESET_SLEEPY_TIMER")
    return wrapper

SAMPLE_RATE = int(_get_env("SAMPLE_RATE", "16000"))
CHANNELS = int(_get_env("CHANNELS", "1"))
DTYPE = _get_env("DTYPE", "int16")
MODEL_NAME = _get_env("MODEL_NAME", "gemini-2.5-flash")
PROMPT_TEXT = (
    "ë‹¤ìŒì€ ì‚¬ìš©ìì˜ í•œêµ­ì–´ ìŒì„±ì…ë‹ˆë‹¤. ì •í™•í•œ ìµœì¢… ì „ì‚¬ë§Œ ì¶œë ¥í•˜ì„¸ìš”."
    " ê·œì¹™: (1) ì‚¬ëŒ ë°œí™”ë§Œ, (2) ë°°ê²½ìŒ/ì¤‘ì–¼ê±°ë¦¼/ë¹„ì–¸ì–´ìŒì€ ì‚­ì œ,"
    " (3) ì¢…ê²°ì–´ë¯¸Â·ë„ì–´ì“°ê¸°Â·ë¬¸ì¥ë¶€í˜¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ, (4) ê¸°í˜¸ë‚˜ ì² ìê°€ í—·ê°ˆë¦¬ë©´ ì˜ë¯¸ê°€ ëª…í™•í•œ í‘œí˜„ìœ¼ë¡œ,"
    " (5) 'ì¶¤', 'ê·¸ë§Œ' ê°™ì€ ì§€ì‹œì–´ëŠ” ê·¸ëŒ€ë¡œ ë³´ì¡´. ì˜¤ì§ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥."
)
SYSTEM_INSTRUCTION = _get_env(
    "SYSTEM_INSTRUCTION",
    "ë„ˆëŠ” ê³µê° ì„œë¹„ìŠ¤ ë¡œë´‡ 'ëª¨í‹°'ì•¼. í•œêµ­ì–´ë¡œ 1~2ë¬¸ì¥, ë”°ëœ»í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µí•´."
    " ì‚¬ìš©ìì˜ ì •ì„œ ì‹ í˜¸(í”¼ê³¤, ìŠ¤íŠ¸ë ˆìŠ¤, ë¶ˆì•ˆ)ë¥¼ ë°˜ì˜í•´ ê³µê°í•˜ê³ ,"
    " ì‚¬ì‹¤ì´ ë¶ˆí™•ì‹¤í•˜ë©´ ì§§ê²Œ í™•ì¸ ì§ˆë¬¸ì„ í•´. ê³¼ì¥Â·ê°€ìŠ¤ë¼ì´íŒ… ê¸ˆì§€."
)
TTS_RATE = int(_get_env("TTS_RATE", "0"))
TTS_VOLUME = int(_get_env("TTS_VOLUME", "100"))
TTS_FORCE_VOICE_ID = _get_env("TTS_FORCE_VOICE_ID", "")
TTS_OUTPUT_DEVICE = _get_env("TTS_OUTPUT_DEVICE", "")
GREETING_TEXT = _get_env("GREETING_TEXT", "ì•ˆë…•í•˜ì„¸ìš”! ëª¨í‹°ì…ë‹ˆë‹¤.")
FAREWELL_TEXT = _get_env("FAREWELL_TEXT", "ë„ì›€ì´ ë˜ì—ˆê¸¸ ë°”ë¼ìš”. ì–¸ì œë“  ë‹¤ì‹œ ë¶ˆëŸ¬ì£¼ì„¸ìš”.")
ENABLE_GREETING = _get_env("ENABLE_GREETING", "1") not in ("0", "false", "False")

def _extract_text(resp) -> str:
    t = getattr(resp, "text", None)
    if t and str(t).strip():
        return str(t).strip()
    try:
        pieces = []
        for c in getattr(resp, "candidates", []) or []:
            content = getattr(c, "content", None)
            if not content: continue
            for p in getattr(content, "parts", []) or []:
                pt = getattr(p, "text", None)
                if pt and str(pt).strip():
                    pieces.append(str(pt).strip())
        if pieces:
            return "\n".join(pieces).strip()
    except Exception: pass
    try: return str(resp).strip()
    except Exception: return ""

@dataclass
class RecorderState:
    recording: bool = False
    frames_q: queue.Queue = queue.Queue()
    stream: sd.InputStream | None = None

class SapiTTSWorker:
    def __init__(self):
        self._q: queue.Queue[str | dict | None] = queue.Queue()
        self.voice_id: str | None = None
        self.output_device_desc: str | None = None
        self.ready = threading.Event()
        self.thread = threading.Thread(target=self._run, daemon=False)
    def start(self):
        self.thread.start()
        self.ready.wait(timeout=5)
    def speak(self, data):
        if not data: return
        text = data if isinstance(data, str) else data.get("text", "")
        print(f"ğŸ”Š TTS enqueue ({len(text)} chars)")
        self._q.put(data)
    
    def wait(self):
        """TTS íì˜ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤."""
        self._q.join()

    def close_and_join(self, drain: bool = True, timeout: float = 15.0):
        try:
            if drain:
                print("â³ TTS ëŒ€ê¸°: í ë¹„ìš°ëŠ” ì¤‘...")
                self._q.join()
            self._q.put(None)
            self.thread.join(timeout=timeout)
        except Exception: pass
    def _run(self):
        pc = None; w32 = None
        try:
            if not IS_WINDOWS:
                print("â„¹ï¸ SAPIëŠ” Windows ì „ìš©ì…ë‹ˆë‹¤. (macOSì—ì„œëŠ” ë¹„í™œì„±)"); self.ready.set(); return
            import pythoncom as pc
            import win32com.client as w32
            pc.CoInitialize()
            voice = w32.Dispatch("SAPI.SpVoice")
            voices = voice.GetVoices()
            chosen_voice_id = None
            if TTS_FORCE_VOICE_ID:
                for i in range(voices.Count):
                    v = voices.Item(i)
                    if v.Id == TTS_FORCE_VOICE_ID: chosen_voice_id = v.Id; break
                if not chosen_voice_id: print(f"â„¹ï¸ TTS_FORCE_VOICE_IDë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {TTS_FORCE_VOICE_ID}")
            if not chosen_voice_id:
                for i in range(voices.Count):
                    v = voices.Item(i)
                    blob = f"{v.Id} {v.GetDescription()}".lower()
                    if any(t in blob for t in ["ko", "korean", "í•œêµ­ì–´"]): chosen_voice_id = v.Id; break
                if not chosen_voice_id and voices.Count > 0: chosen_voice_id = voices.Item(0).Id
            if chosen_voice_id:
                for i in range(voices.Count):
                    v = voices.Item(i)
                    if v.Id == chosen_voice_id: voice.Voice = v; self.voice_id = v.Id; break
            outs = voice.GetAudioOutputs()
            chosen_out_desc = None
            if TTS_OUTPUT_DEVICE:
                key = TTS_OUTPUT_DEVICE.lower()
                for i in range(outs.Count):
                    o = outs.Item(i); desc = o.GetDescription()
                    if key in desc.lower(): voice.AudioOutput = o; chosen_out_desc = desc; break
                if not chosen_out_desc: print(f"â„¹ï¸ ì§€ì •í•œ ì¶œë ¥ ì¥ì¹˜ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {TTS_OUTPUT_DEVICE}")
            if not chosen_out_desc and outs.Count > 0:
                try: desc = outs.Item(0).GetDescription()
                except Exception: desc = "System Default"
                chosen_out_desc = desc
            self.output_device_desc = chosen_out_desc
            try: voice.Rate = max(-10, min(10, TTS_RATE))
            except Exception: pass
            try: voice.Volume = max(0, min(100, TTS_VOLUME))
            except Exception: pass

            default_rate = voice.Rate
            default_volume = voice.Volume

            print("ğŸ§ ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ëª©ë¡ (SAPI):")
            for i in range(voices.Count): v = voices.Item(i); print(f"  - [{i}] id='{v.Id}', desc='{v.GetDescription()}'")
            print("ğŸ”‰ ì‚¬ìš© ê°€ëŠ¥í•œ ì¶œë ¥ ì¥ì¹˜ (SAPI):")
            for i in range(outs.Count): o = outs.Item(i); print(f"  - [{i}] '{o.GetDescription()}'")
            print(f"â–¶ ì„ íƒëœ ìŒì„± id='{self.voice_id}'")
            print(f"â–¶ ì„ íƒëœ ì¶œë ¥='{self.output_device_desc}'")
            self.ready.set()
            voice.Speak("T T Sê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
            while True:
                item = self._q.get()
                if item is None: self._q.task_done(); break
                try:
                    if isinstance(item, dict):
                        text = item.get("text")
                        voice.Rate = item.get("rate", default_rate)
                        voice.Volume = item.get("volume", default_volume)
                    else:
                        text = item

                    if text:
                        print("ğŸ”ˆ TTS speaking..."); 
                        voice.Speak(text, 1); 
                        print("âœ… TTS done")

                finally:
                    voice.Rate = default_rate
                    voice.Volume = default_volume
                    self._q.task_done()
        except Exception as e: print(f"â„¹ï¸ TTS ìŠ¤ë ˆë“œ ì˜¤ë¥˜: {e}"); self.ready.set()
        finally:
            try:
                if pc is not None: pc.CoUninitialize()
            except Exception: pass

class TypecastTTSWorker:
    def __init__(self):
        self._q: queue.Queue[str | dict | None] = queue.Queue()
        self.ready = threading.Event()
        self.thread = threading.Thread(target=self._run, daemon=False)
    def start(self):
        self.thread.start(); self.ready.wait(timeout=5)
    def speak(self, data):
        if not data: return
        text = data if isinstance(data, str) else data.get("text", "")
        print(f"ğŸ”Š TTS enqueue ({len(text)} chars)")
        self._q.put(data)

    def wait(self):
        """TTS íì˜ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤."""
        self._q.join()

    def close_and_join(self, drain: bool = True, timeout: float = 30.0):
        try:
            if drain: self._q.join()
            self._q.put(None); self.thread.join(timeout=timeout)
        except Exception: pass
    def _run(self):
        try:
            api_key = _get_env("TYPECAST_API_KEY")
            voice_id = _get_env("TYPECAST_VOICE_ID")
            if not api_key or not voice_id:
                print("â— TYPECAST_API_KEY ë˜ëŠ” TYPECAST_VOICE_IDê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."); self.ready.set(); return
            model = _get_env("TYPECAST_MODEL", "ssfm-v21")
            language = _get_env("TYPECAST_LANGUAGE", "kor")
            audio_format = _get_env("TYPECAST_AUDIO_FORMAT", "wav")
            emotion = _get_env("TYPECAST_EMOTION", "")
            intensity = float(_get_env("TYPECAST_EMOTION_INTENSITY", "1.0") or "1.0")
            seed_env = _get_env("TYPECAST_SEED", "")
            seed = int(seed_env) if (seed_env and seed_env.isdigit()) else None
            self.ready.set()
            print("â–¶ Typecast TTS ì¤€ë¹„ ì™„ë£Œ")
            url = "https://api.typecast.ai/v1/text-to-speech"
            headers = {"X-API-KEY": api_key, "Content-Type": "application/json"}
            while True:
                item = self._q.get()
                if item is None: self._q.task_done(); break
                try:
                    if isinstance(item, dict):
                        text = item.get("text")
                        rate_sapi = item.get("rate", 0) 
                        rate_multiplier = 1.0 + (rate_sapi / 10.0) * 0.5 
                        volume = item.get("volume", 100)
                        pitch = item.get("pitch", 0)
                    else:
                        text = item
                        rate_multiplier = 1.0
                        volume = 100
                        pitch = 0

                    if not text: continue
                    
                    payload = {
                        "voice_id": voice_id, "text": text, "model": model, "language": language, 
                        "output": {
                            "volume": volume, 
                            "audio_pitch": pitch, 
                            "audio_tempo": rate_multiplier, 
                            "audio_format": audio_format
                        }
                    }
                    if emotion: payload["prompt"] = {"emotion_preset": emotion, "emotion_intensity": intensity}
                    if seed is not None: payload["seed"] = seed
                    r = requests.post(url, headers=headers, json=payload, timeout=60)
                    if r.status_code == 200:
                        data = r.content
                        with io.BytesIO(data) as buf:
                            with wave.open(buf, "rb") as wf:
                                sr = wf.getframerate(); sampwidth = wf.getsampwidth(); frames = wf.readframes(wf.getnframes())
                        if sampwidth == 2: audio = np.frombuffer(frames, dtype=np.int16).astype(np.float32) / 32768.0
                        else: audio = np.frombuffer(frames, dtype=np.int16).astype(np.float32) / 32768.0
                        sd.play(audio, sr); sd.wait(); print("âœ… TTS done")
                    else: print(f"âŒ Typecast ì˜¤ë¥˜ {r.status_code}: {r.text[:200]}")
                finally: self._q.task_done()
        except Exception as e: print(f"â„¹ï¸ Typecast TTS ìŠ¤ë ˆë“œ ì˜¤ë¥˜: {e}"); self.ready.set()

class PressToTalk:
    def __init__(self,
                 start_dance_cb: Optional[Callable[[], None]] = None,
                 stop_dance_cb: Optional[Callable[[], None]] = None,
                 play_rps_motion_cb: Optional[Callable[[], None]] = None,
                 emotion_queue: Optional[queue.Queue] = None,
                 hotword_queue: Optional[queue.Queue] = None,
                 stop_event: Optional[threading.Event] = None,
                 rps_command_q: Optional[multiprocessing.Queue] = None,
                 rps_result_q: Optional[multiprocessing.Queue] = None,
                 sleepy_event: Optional[threading.Event] = None,
                 shared_state: Optional[dict] = None,
                 ox_command_q: Optional[multiprocessing.Queue] = None,
                 ):
        
        api_key = os.environ.get("GOOGLE_API_KEY")
        if not api_key or not api_key.strip():
            print("â— GOOGLE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤."); sys.exit(1)

        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(MODEL_NAME)
        self.chat = genai.GenerativeModel(MODEL_NAME, system_instruction=SYSTEM_INSTRUCTION).start_chat(history=[])

        self.router_model = genai.GenerativeModel(
            MODEL_NAME,
            system_instruction=(
                "ë„ˆëŠ” ëª…ë ¹ ë¼ìš°í„°ë‹¤. í•œêµ­ì–´ ë¬¸ì¥ì„ ë³´ê³  ì˜ë„ë¥¼ ë¶„ë¥˜í•œë‹¤. "
                "dance=ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ì¶¤ì„ 'ì‹œì‘í•˜ë¼ê³ ' ëª…ë ¹/ìš”ì²­/ìŠ¹ì¸. "
                "game=ê°€ìœ„ë°”ìœ„ë³´ ê²Œì„ì„ ì‹œì‘í•˜ìëŠ” ìš”ì²­. "
                "ox_quiz=ì–¼êµ´ ì¸ì‹ OX í€´ì¦ˆ ê²Œì„ì„ ì‹œì‘í•˜ìëŠ” ìš”ì²­. "
                "joke=ê°œê·¸ë‚˜ ë†ë‹´ì„ í•´ë‹¬ë¼ëŠ” ëª…í™•í•œ ìš”ì²­. "  # "joke" ì˜ë„ ì •ì˜ ì¶”ê°€
                "stop=ì¶¤ì„ 'ë©ˆì¶”ë¼'ëŠ” ëª…ë ¹/ìš”ì²­/ìŠ¹ì¸. "
                "chat=ì¼ë°˜ ëŒ€í™”(ì§ˆë¬¸/ì¡ë‹´/ì„¤ëª…/ê°ì •í‘œí˜„/ì¶¤ì— ëŒ€í•œ ê²¬í•´Â·ê°€ì •ì  ì§ˆë¬¸ í¬í•¨). "
                "ë¶€ì •/ê¸ˆì§€/ê±°ì ˆ í‘œí˜„(ì˜ˆ:'ì¶¤ ì¶”ì§€ ë§ˆ','ì¶¤ì€ ì•ˆë¼','ê·¸ë§Œë‘ì§€ ë§ê³  ê³„ì†')ì€ ì •í™•íˆ ë°˜ì˜í•˜ë¼. "
                "ì˜¤ì§ ì•„ë˜ JSONë§Œ ì¶œë ¥:\n"
                '{ "intent": "dance|stop|game|ox_quiz|chat|joke", "normalized_text": "<ì˜ë¯¸ë§Œ ë³´ì¡´í•œ ê°„ê²°í•œ ë¬¸ì¥>", '
                '"speakable_reply": "<ì˜ë„ê°€ chatì¼ ë•Œ 1~2ë¬¸ì¥ ê³µê°í˜• ì§§ì€ ë‹µë³€. dance/stop/game/joke/ox_quizì´ë©´ ë¹ˆ ë¬¸ìì—´>" }'
            ),
            generation_config={"response_mime_type": "application/json", "temperature": 0.2}
        )
        
        self.start_dance_cb = start_dance_cb
        self.stop_dance_cb  = stop_dance_cb
        self.play_rps_motion_cb = play_rps_motion_cb
        self.emotion_queue = emotion_queue
        self.hotword_queue = hotword_queue
        self.stop_event = stop_event or threading.Event()
        
        self.last_activity_time = 0
        self.current_listener = None

        self.rps_command_q = rps_command_q
        self.rps_result_q  = rps_result_q
        self.ox_command_q = ox_command_q
        self.busy_lock = threading.Lock()
        self.busy_signals = 0
        self.background_keep_alive_thread = None
        self.stop_background_keep_alive = threading.Event()

        default_engine = "sapi" if IS_WINDOWS else "typecast"
        engine = _get_env("TTS_ENGINE", default_engine).lower()
        if engine == "sapi" and not IS_WINDOWS: engine = "typecast"
        if engine == "typecast": self.tts = TypecastTTSWorker()
        else: self.tts = SapiTTSWorker()
        self.tts.start()

        self.state = RecorderState()
        self._print_intro()
        if ENABLE_GREETING:
            self.tts.speak(GREETING_TEXT)
            if self.emotion_queue: self.emotion_queue.put("NEUTRAL")

        self.sleepy_event = sleepy_event
        self.shared_state = shared_state

        if self.sleepy_event:
            self.snoring_thread = threading.Thread(target=self._snoring_worker, daemon=True)
            self.snoring_thread.start()
        
    def _print_intro(self):
        print("\n=== Gemini PTT (í†µí•© ë²„ì „) ===")
        print("â–¶ 'ì•ˆë…• ëª¨í‹°'ë¡œ í˜¸ì¶œ(SLEEPY ìƒíƒœ) â†’ ìŠ¤í˜ì´ìŠ¤ë°”ë¡œ ëŒ€í™”(NEUTRAL ìƒíƒœ) â†’ ESCë¡œ ì¢…ë£Œ")
        print("â–¶ [User ] ì „ì‚¬ ê²°ê³¼ / [Gemini] ëª¨ë¸ ë‹µë³€")
        print("â–¶ í‚¤ì›Œë“œ: 'ì¶¤' â†’ ëŒ„ìŠ¤ ì‹œì‘ / 'ê·¸ë§Œ' â†’ ëŒ„ìŠ¤ ì •ì§€ / 'ê°€ìœ„ë°”ìœ„ë³´' â†’ ê²Œì„ ì‹œì‘ / 'OX ê²Œì„")
        print(f"â–¶ MODEL={MODEL_NAME}, SR={SAMPLE_RATE}Hz")
        v_id, out_desc = getattr(self.tts, "voice_id", None), getattr(self.tts, "output_device_desc", None)
        if v_id: print(f"â–¶ TTS Voice : {v_id}")
        if out_desc: print(f"â–¶ TTS Output: {out_desc}")
        print("----------------------------------------------------------------\n")

    def raise_busy_signal(self):
        """ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘ì„ ì•Œë¦¬ê³ , í•„ìš”í•˜ë©´ keep-alive ìŠ¤ë ˆë“œë¥¼ í™œì„±í™”í•©ë‹ˆë‹¤."""
        with self.busy_lock:
            self.busy_signals += 1
            print(f"âš¡ ë°”ì¨ ì‹ í˜¸ ì¦ê°€ (í˜„ì¬: {self.busy_signals})")
            if self.busy_signals == 1 and self.emotion_queue:
                self.stop_background_keep_alive.clear()
                
                def worker():
                    while not self.stop_background_keep_alive.wait(5.0):
                        if self.emotion_queue:
                            self.emotion_queue.put("RESET_SLEEPY_TIMER")
                    print("â˜• ë°±ê·¸ë¼ìš´ë“œ keep-alive ìì—° ì¢…ë£Œ")

                self.background_keep_alive_thread = threading.Thread(target=worker, daemon=True)
                self.background_keep_alive_thread.start()
                print("ğŸƒ ë°±ê·¸ë¼ìš´ë“œ keep-alive ì‹œì‘ë¨")

    def lower_busy_signal(self):
        """ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì¢…ë£Œë¥¼ ì•Œë¦¬ê³ , ëª¨ë“  ì‘ì—…ì´ ëë‚˜ë©´ keep-alive ìŠ¤ë ˆë“œë¥¼ ì¤‘ì§€í•©ë‹ˆë‹¤."""
        with self.busy_lock:
            self.busy_signals = max(0, self.busy_signals - 1)
            print(f"âš¡ ë°”ì¨ ì‹ í˜¸ ê°ì†Œ (í˜„ì¬: {self.busy_signals})")
            if self.busy_signals == 0:
                self.stop_background_keep_alive.set()
                self.background_keep_alive_thread = None
                self.last_activity_time = time.time()
                print("âœ… ëª¨ë“  ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì™„ë£Œ. keep-alive ì¤‘ì§€ë¨")
                print("âœ… RESET_SLEEPY_TIMER")

    def _audio_callback(self, indata, frames, time_info, status):
        if status: print(f"[ì˜¤ë””ì˜¤ ê²½ê³ ] {status}", file=sys.stderr)
        self.state.frames_q.put(indata.copy())

    def _start_recording(self):
        if self.state.recording: return
        if self.emotion_queue:
            self.emotion_queue.put("RESET_SLEEPY_TIMER")

        while not self.state.frames_q.empty():
            try: self.state.frames_q.get_nowait()
            except queue.Empty: break
        device_idx = None
        env_dev = os.environ.get("INPUT_DEVICE_INDEX")
        if env_dev and env_dev.strip():
            try: device_idx = int(env_dev.strip())
            except Exception: device_idx = None
        if device_idx is None:
            env_name = os.environ.get("INPUT_DEVICE_NAME", "")
            if env_name: device_idx = _find_input_device_by_name(env_name)
        try:
            if device_idx is not None: dinfo = sd.query_devices(device_idx, 'input')
            else: default_in = sd.default.device[0]; dinfo = sd.query_devices(default_in, 'input')
            print(f"ğŸšï¸  ì…ë ¥ ì¥ì¹˜: {dinfo['name']}")
        except Exception: pass
        self.state.stream = sd.InputStream(samplerate=SAMPLE_RATE, channels=CHANNELS, dtype=DTYPE, callback=self._audio_callback, blocksize=0, device=device_idx)
        self.state.stream.start()
        self.state.recording = True
        print("ğŸ™ï¸  ë…¹ìŒ ì‹œì‘ (ìŠ¤í˜ì´ìŠ¤ë°” ìœ ì§€ ì¤‘)...")

    def _stop_recording_and_transcribe(self):
        if not self.state.recording: return
        print("â¹ï¸  ë…¹ìŒ ì¢…ë£Œ, ì „ì‚¬ ì¤‘...")
        self.state.recording = False
        try:
            if self.state.stream: self.state.stream.stop(); self.state.stream.close()
        finally: self.state.stream = None
        chunks = []
        while not self.state.frames_q.empty(): chunks.append(self.state.frames_q.get())
        if not chunks: print("(ë…¹ìŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.)\n"); return
        audio_np = np.concatenate(chunks, axis=0)
        wav_bytes = self._to_wav_bytes(audio_np, SAMPLE_RATE, CHANNELS, DTYPE)
        threading.Thread(target=self._transcribe_then_chat, args=(wav_bytes,), daemon=True).start()

    @staticmethod
    def _to_wav_bytes(audio_np: np.ndarray, samplerate: int, channels: int, dtype: str) -> bytes:
        with io.BytesIO() as buf:
            with wave.open(buf, 'wb') as wf:
                wf.setnchannels(channels); wf.setsampwidth(np.dtype(dtype).itemsize)
                wf.setframerate(samplerate); wf.writeframes(audio_np.tobytes())
            return buf.getvalue()

    def _route_intent(self, text: str) -> dict:
        try:
            resp = self.router_model.generate_content(text)
            raw = _extract_text(resp); data = json.loads(raw)
            if not isinstance(data, dict): raise ValueError("router JSON is not a dict")
            intent = data.get("intent", "chat")
            if intent not in ("dance", "stop", "game", "chat", "joke", "ox_quiz"): intent = "chat"
            return {"intent": intent, "normalized_text": str(data.get("normalized_text", text)), "speakable_reply": str(data.get("speakable_reply", "")) if intent == "chat" else ""}
        except Exception as e:
            print(f"(router í´ë°±) {e}")
            low = text.lower()
            if any(neg in text for neg in ["í•˜ì§€ ë§ˆ", "í•˜ì§€ë§ˆ", "ì•ˆë¼", "ì•ˆ ë¼", "ê·¸ë§Œë‘ì§€ ë§ˆ", "ë©ˆì¶”ì§€ ë§ˆ"]): return {"intent": "chat", "normalized_text": text, "speakable_reply": ""}
            if "ê·¸ë§Œ" in text: return {"intent": "stop", "normalized_text": text, "speakable_reply": ""}
            if "ì¶¤" in text: return {"intent": "dance", "normalized_text": text, "speakable_reply": ""}
            if any(w in low for w in ["ë†ë‹´", "ê°œê·¸"]): return {"intent": "joke", "normalized_text": text, "speakable_reply": ""}
            if "ox í€´ì¦ˆ" in low or "oxê²Œì„" in low or "ox ê²Œì„" in low: return {"intent": "ox_quiz", "normalized_text": text, "speakable_reply": ""}
            if any(w in low for w in ["ê°€ìœ„ë°”ìœ„ë³´", "ê²Œì„"]): return {"intent": "game", "normalized_text": text, "speakable_reply": ""}
            return {"intent": "chat", "normalized_text": text, "speakable_reply": ""}
    
    def _analyze_and_send_emotion(self, text: str):
        if not self.emotion_queue or not text: return
        low_text = text.lower()
        if any(w in low_text for w in ["ì‹ ë‚˜", "ì¬ë°Œ", "ì¢‹ì•„", "í–‰ë³µ", "ìµœê³ "]): self.emotion_queue.put("HAPPY")
        elif any(w in low_text for w in ["ë†€ë¼ìš´", "ë†€ë", "ê¹œì§", "ì„¸ìƒì—"]): self.emotion_queue.put("SURPRISED")
        elif any(w in low_text for w in ["ìŠ¬í¼", "ìš°ìš¸", "í˜ë“¤", "ì†ìƒ"]): self.emotion_queue.put("SAD")
        elif any(w in low_text for w in ["í™”ë‚˜", "ì§œì¦", "ì‹«ì–´", "ìµœì•…"]): self.emotion_queue.put("ANGRY")
        elif any(w in low_text for w in ["ì‚¬ë‘", "ë‹¤ì •", "ë”°ëœ»", "ê³ ë§ˆì›Œ"]): self.emotion_queue.put("TENDER")
        elif any(w in low_text for w in ["ê¶ê¸ˆ", "ìƒê°", "ê¸€ì„", "í .."]): self.emotion_queue.put("THINKING")
        else: self.emotion_queue.put("NEUTRAL")

    @keep_awake
    def _transcribe_then_chat(self, wav_bytes: bytes):
        try:
            b64 = base64.b64encode(wav_bytes).decode("ascii")
            parts = [{"text": PROMPT_TEXT}, {"inline_data": {"mime_type": "audio/wav", "data": b64}}]
            resp = self.model.generate_content(parts)
            user_text = _extract_text(resp)
            if not user_text: print("ğŸ“ ì „ì‚¬ ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.\n"); return
            ts = datetime.now().strftime("%H:%M:%S"); print(f"[{ts}] [User ] {user_text}")
            route = self._route_intent(user_text)
            intent, model_text, speak_text = route["intent"], "", ""

            if intent == "chat":
                if route.get("speakable_reply"): model_text = route["speakable_reply"]
                else: reply = self.chat.send_message(user_text); model_text = _extract_text(reply) or ""
                speak_text = model_text
                self._analyze_and_send_emotion(model_text) 

            elif intent == "dance":
                print("ğŸ’¡ ì˜ë„: DANCE START")
                if callable(self.start_dance_cb):
                    try: 
                        self.raise_busy_signal() 
                        self.start_dance_cb()
                    except Exception as e: print(f"âš ï¸ start_dance_cb ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                
                if self.emotion_queue:
                    chosen_emotion = random.choice(["EXCITED"])
                    self.emotion_queue.put(chosen_emotion)
                    print(f"ğŸ’ƒ ì¶¤ ì‹œì‘! í‘œì •ì„ {chosen_emotion}ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.")

                model_text = "ë„¤! ëª¨í‹°ê°€ ì¶¤ì„ ì¶°ë³¼ê²Œìš”"; speak_text = "ë„¤! ëª¨í‹°ê°€ ì¶¤ì„ ì¶°ë³¼ê²Œìš”"

            elif intent == "stop":
                print("ğŸ’¡ ì˜ë„: DANCE STOP")
                if callable(self.stop_dance_cb):
                    try: 
                        self.stop_dance_cb()
                        self.lower_busy_signal() 
                    except Exception as e: print(f"âš ï¸ stop_dance_cb ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                
                if self.emotion_queue: self.emotion_queue.put("NEUTRAL")
                model_text = "(ì¶¤ ì •ì§€ ëª…ë ¹ ì²˜ë¦¬)"

            elif intent == "joke":
                print("ğŸ’¡ ì˜ë„: JOKE (AI í”„ë¡¬í”„íŠ¸ ìƒì„± ë°©ì‹)")
                try:
                    self.raise_busy_signal()
                    if self.emotion_queue: self.emotion_queue.put("THINKING")

                    # --- 1ë‹¨ê³„: AIì—ê²Œ 'ê°œê·¸ ìºë¦­í„°'ë¥¼ ë§Œë“¤ì–´ë‹¬ë¼ê³  ìš”ì²­ ---
                    meta_prompt = (
                        "ë‹¹ì‹ ì€ 'ëª¨í‹°'ë¼ëŠ” ë¡œë´‡ì—ê²Œ ë†ë‹´ì„ ì‹œí‚¬ ê²ë‹ˆë‹¤. "
                        "ëª¨í‹°ê°€ ë”°ë¼ í•  ìˆ˜ ìˆëŠ”, ì•„ì£¼ ì§§ê³  ë…íŠ¹í•œ 'ë†ë‹´ ìŠ¤íƒ€ì¼' ë˜ëŠ” 'ë†ë‹´í•˜ëŠ” ìºë¦­í„°'ë¥¼ ë”± í•œ ë¬¸ì¥ìœ¼ë¡œë§Œ ì°½ì˜ì ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”. "
                        "ì˜ˆì‹œ: 'ìˆ˜ì¤ìŒì´ ë§ì§€ë§Œ í•  ë§ì€ ë‹¤ í•˜ëŠ” ë¡œë´‡', 'ì¸ê°„ì˜ ê°ì •ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ë¶„ì„í•˜ë©° ë†ë‹´í•˜ëŠ” AI ë°•ì‚¬'"
                    )
                    
                    # ìƒˆë¡œìš´ ëŒ€í™” ì„¸ì…˜ì„ ì‹œì‘í•˜ì—¬ ìºë¦­í„° ìƒì„± (ê¸°ì¡´ ëŒ€í™”ì— ì˜í–¥ X)
                    style_response = genai.GenerativeModel(MODEL_NAME).generate_content(meta_prompt)
                    joke_style = _extract_text(style_response)

                    # ë§Œì•½ ìŠ¤íƒ€ì¼ ìƒì„±ì— ì‹¤íŒ¨í•˜ë©´ ê¸°ë³¸ ìŠ¤íƒ€ì¼ì„ ì‚¬ìš©
                    if not joke_style:
                        joke_style = "ì•„ì¬ ê°œê·¸ë¥¼ ì¢‹ì•„í•˜ëŠ” ë¡œë´‡"

                    print(f"   - ìƒì„±ëœ ë†ë‹´ ìŠ¤íƒ€ì¼: {joke_style}")

                    # --- 2ë‹¨ê³„: ìƒì„±ëœ 'ê°œê·¸ ìºë¦­í„°'ë¡œ ì‹¤ì œ ë†ë‹´ ìš”ì²­ ---
                    joke_prompt = f"ë„ˆëŠ” '{joke_style}'ì´ë¼ëŠ” ì—­í• ì„ ë§¡ì€ ë¡œë´‡ 'ëª¨í‹°'ì•¼. ê·¸ ì—­í• ì— ë§ì¶°ì„œ ì–´ë¦°ì•„ì´ë„ ì´í•´í•  ìˆ˜ ìˆëŠ” ë§¤ìš° ì§§ì€ ê°œê·¸ë¥¼ ë”± í•˜ë‚˜ë§Œ í•´ì¤˜. ì¤‘ìš”í•œ ê·œì¹™: ê´„í˜¸ë¥¼ ì‚¬ìš©í•œ í–‰ë™ ë¬˜ì‚¬ë‚˜ ë¶€ê°€ ì„¤ëª…(ì˜ˆ: (ì›ƒìŒ), (ìœ™í¬))ì€ ì ˆëŒ€ë¡œ ì¶œë ¥í•˜ì§€ ë§ˆ. ê·¸ë¦¬ê³  ë„ˆì—ê²Œ ì£¼ì–´ì§„ ì—­í• ì´ë‚˜ ìŠ¤íƒ€ì¼ì— ëŒ€í•´ ì ˆëŒ€ ì–¸ê¸‰í•˜ê±°ë‚˜ ì„¤ëª…í•˜ì§€ ë§ê³ , ì˜¤ì§ ìµœì¢… ë†ë‹´ë§Œ ë§í•´."
                    
                    response = self.chat.send_message(joke_prompt)
                    joke = _extract_text(response)

                    # ë†ë‹´ ìƒì„± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë‹µë³€
                    if not joke:
                        joke = "ì•—, ì¬ë¯¸ìˆëŠ” ë†ë‹´ì´ ë– ì˜¤ë¥´ì§€ ì•Šë„¤ìš”. ë‹¤ìŒì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”!"

                    model_text = joke
                    speak_text = joke
                    
                    if self.emotion_queue: self.emotion_queue.put("HAPPY")
                finally:
                    self.lower_busy_signal()

            elif intent == "ox_quiz":
                print("ğŸ’¡ ì˜ë„: OX QUIZ GAME (ë¼ìš´ë“œ ë°©ì‹)")

                if not self.shared_state or not self.ox_command_q:
                    self.tts.speak("ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ í€´ì¦ˆë¥¼ ì§„í–‰í•  ìˆ˜ ì—†ì–´ìš”.")
                    print("âŒ shared_state ë˜ëŠ” ox_command_qê°€ ì—†ì–´ ëª¨ë“œ ì „í™˜ ë¶ˆê°€")
                    return
                
                predefined_quizzes = [
                    {"question": "ì œ ì´ë¦„ì€ ëª¨í„°ì…ë‹ˆë‹¤", "answer": "X", "explanation": "ì œ ì´ë¦„ì€ ëª¨í‹°, ëª¨í‹°ì˜ˆìš”! ê¼­ ê¸°ì–µí•´ì£¼ì„¸ìš”."},
                    {"question": "ëª¨í‹°ëŠ” ê³µê° ì„œë¹„ìŠ¤ ë¡œë´‡ì…ë‹ˆë‹¤", "answer": "O", "explanation": "ì €ëŠ” ì—¬ëŸ¬ë¶„ì˜ ë§ˆìŒì„ ì´í•´í•˜ê³  ê³µê°í•˜ê¸° ìœ„í•´ ë§Œë“¤ì–´ì¡Œì–´ìš”."},
                    {"question": "ëª¨í‹°ëŠ” ì¶¤ì„ ì¶œ ìˆ˜ ìˆë‹¤", "answer": "O", "explanation": "ì¶¤ í•œë²ˆ ë³´ì—¬ë“œë¦´ê¹Œìš”?"},
                    {"question": "ëª¨í‹°ëŠ” ìœ íŠœë²„ì´ë‹¤", "answer": "O", "explanation": "êµ¬ë…ê³¼ ì¢‹ì•„ìš” ì•Œë¦¼ ì„¤ì •ê¹Œì§€ ê¾¸ìš±"},
                    {"question": "ëª¨í‹°ëŠ” ë†ë‹´ì„ ì˜í•œë‹¤", "answer": "O", "explanation": "ì œê°€ ìƒê°í•´ë„ ê·¸ëŸ° ê²ƒ ê°™ì•„ìš”! ì–¸ì œë“  'ë†ë‹´í•´ì¤˜'ë¼ê³  ë§í•´ë³´ì„¸ìš”."}
                ]
                quiz_round_counter = 0

                is_first_round = True
                try:
                    self.raise_busy_signal()
                    self.shared_state['mode'] = 'ox_quiz'
                    if self.emotion_queue: self.emotion_queue.put("THINKING")
                    
                    is_game_over = False
                    while not is_game_over and not self.stop_event.is_set():
                        quiz_data = None
                        is_predefined = False

                        if quiz_round_counter < len(predefined_quizzes):
                            # ì‚¬ì „ ì •ì˜ëœ í€´ì¦ˆ ì‚¬ìš©
                            quiz_data = predefined_quizzes[quiz_round_counter]
                            is_predefined = True 
                            print(f"  - ì‚¬ì „ ì •ì˜ëœ í€´ì¦ˆ #{quiz_round_counter + 1} ì‚¬ìš©: {quiz_data}")
                            quiz_round_counter += 1

                        else:
                            print("  - ì‚¬ì „ ì •ì˜ëœ í€´ì¦ˆ ì†Œì§„. Gemini APIë¡œ ìƒˆ í€´ì¦ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

                            # 1. Geminië¥¼ í†µí•´ ë™ì ìœ¼ë¡œ í€´ì¦ˆ ìƒì„±
                            quiz_prompt = (
                                "ì–´ë¦°ì´ë„ ì´í•´í•  ìˆ˜ ìˆëŠ”, ì¬ë¯¸ìˆê³  ê°„ë‹¨í•œ ìƒì‹ OX í€´ì¦ˆë¥¼ í•œêµ­ì–´ë¡œ í•˜ë‚˜ë§Œ ë§Œë“¤ì–´ì¤˜. "
                                "ì´ì „ì— ì¶œì œí–ˆë˜ ë¬¸ì œì™€ëŠ” ë‹¤ë¥¸ ìƒˆë¡œìš´ ì£¼ì œë¡œ ë‚´ì¤˜."
                                "ì¶œë ¥ì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì´ì–´ì•¼ í•´. ë‹¤ë¥¸ ì„¤ëª…ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆ.\n"
                                '{ "question": "<í€´ì¦ˆ ì§ˆë¬¸>", "answer": "O ë˜ëŠ” X" }'
                            )

                            try:
                                quiz_response = genai.GenerativeModel(MODEL_NAME).generate_content(
                                    quiz_prompt, 
                                    generation_config={"response_mime_type": "application/json"}
                                )
                                raw_json = _extract_text(quiz_response)
                                quiz_data = json.loads(raw_json)
                                print(f"  - ìƒì„±ëœ í€´ì¦ˆ: {quiz_data}")
                            except Exception as e:
                                print(f"  - í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨: {e}. í´ë°± í€´ì¦ˆë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                                quiz_data = { "question": "ì‚¬ëŒì€ ì½”ë¡œ ìˆ¨ ì‰¬ê³  ì…ìœ¼ë¡œë„ ìˆ¨ ì‰´ ìˆ˜ ìˆë‹¤.", "answer": "O" }

                        # 2. ì‚¬ìš©ìì—ê²Œ í€´ì¦ˆ ë¬¸ì œì™€ ì•ˆë‚´ ìŒì„± ì¶œë ¥
                        if is_first_round:
                            self.tts.speak("OX í€´ì¦ˆë¥¼ ì‹œì‘í•©ë‹ˆë‹¤!")
                        else:
                            self.tts.speak("ì, ë‹¤ìŒ ë¬¸ì œì…ë‹ˆë‹¤!")
                        
                        self.tts.speak(quiz_data["question"])
                        self.tts.wait()
                        self.tts.speak("OëŠ” ì˜¤ë¥¸ìª½ì—, XëŠ” ì™¼ìª½ì— ì„œì£¼ì„¸ìš”.")
                        self.tts.wait()
                        self.tts.speak("5! 4! 3!")
                        self.tts.speak("2! 1!")
                        self.tts.wait()

                        # 3. ì›Œì»¤ì—ê²Œ ì •ë‹µê³¼ í•¨ê»˜ ë¼ìš´ë“œ ì‹œì‘/ì§„í–‰ ëª…ë ¹ ì „ì†¡
                        command_to_send = {
                            "command": "START_OX_QUIZ" if is_first_round else "NEXT_ROUND",
                            "answer": quiz_data["answer"],
                            "is_predefined": is_predefined
                        }
                        self.ox_command_q.put(command_to_send)
                        is_first_round = False

                        # 4. ì›Œì»¤ë¡œë¶€í„° ê²°ê³¼ ìˆ˜ì‹  ëŒ€ê¸° ë° ìŒì„± ì¶œë ¥
                        try:
                            round_result_msg = self.rps_result_q.get(timeout=35)
                            print(f"OX í€´ì¦ˆ ë¼ìš´ë“œ ê²°ê³¼ ìˆ˜ì‹ : {round_result_msg}")
                            self.tts.speak(round_result_msg)
                            self.tts.wait()

                            time.sleep(1) # A short pause for dramatic effect

                            correct_answer_text = f"ì •ë‹µì€ {quiz_data['answer']} ì˜€ìŠµë‹ˆë‹¤!"
                            self.tts.speak(correct_answer_text)
                            self.tts.wait()
                            
                            if is_predefined and quiz_data.get("explanation"):
                                # If it's a predefined quiz with an explanation, speak it
                                self.tts.speak(quiz_data["explanation"])
                                self.tts.wait()

                            # 5. ê²Œì„ ê³„ì† ì—¬ë¶€ íŒë‹¨
                            if is_predefined or "ì‚´ì•„ë‚¨ì•˜ìŠµë‹ˆë‹¤" in round_result_msg:
                                time.sleep(2)
                                
                                continue
                            else:
                                is_game_over = True

                        except queue.Empty:
                            print("OX í€´ì¦ˆ ì‹œê°„ ì´ˆê³¼. ì›Œì»¤ë¡œë¶€í„° ê²°ê³¼ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                            self.tts.speak("ì´ëŸ°, ì‹œê°„ ì•ˆì— ê²°ê³¼ë¥¼ ë°›ì§€ ëª»í–ˆì–´ìš”. ê²Œì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                            is_game_over = True
                    
                    model_text = "OX í€´ì¦ˆ ê²Œì„ ì¢…ë£Œ."

                finally:
                    if self.shared_state:
                        self.shared_state['mode'] = 'tracking'
                    self.lower_busy_signal()
                    if self.emotion_queue: self.emotion_queue.put("NEUTRAL")
                

            elif intent == "game":
                print("ğŸ’¡ ì˜ë„: ROCK PAPER SCISSORS GAME")
                try:
                    self.raise_busy_signal() 
                    self.tts.speak("ê°€ìœ„ë°”ìœ„ë³´ ê²Œì„ì„ ì‹œì‘í• ê²Œìš”. ì ì‹œí›„ ë‹¹ì‹ ì˜ ì†ë™ì‘ì„ ë³´ì—¬ì£¼ì„¸ìš”")
                    time.sleep(1)
                    final_game_result = ""

                    while True: 
                        if self.emotion_queue: self.emotion_queue.put("RESET_SLEEPY_TIMER")
                        self.rps_command_q.put("START_GAME")
                        self.tts.speak("ì¤€ë¹„í•˜ì‹œê³ ...")
                        self.tts.wait()

                        if callable(self.play_rps_motion_cb):
                            threading.Thread(target=self.play_rps_motion_cb, daemon=True).start()

                        self.tts.speak("ê°€ìœ„! ë°”ìœ„!")
                        self.tts.speak("ë³´!")
                        self.tts.wait()

                        game_result = ""
                        try:
                            game_result = self.rps_result_q.get(timeout=20)
                            print(f"ê²Œì„ ê²°ê³¼ ìˆ˜ì‹ : {game_result}")
                            self.tts.speak(game_result)
                            time.sleep(1)
                        except queue.Empty:
                            print("ê²Œì„ ì‹œê°„ ì´ˆê³¼. ì œìŠ¤ì²˜ë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                            game_result = "ì œìŠ¤ì²˜ë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆì–´ìš”."
                            self.tts.speak(game_result)
                        
                        final_game_result = game_result
                        
                        if "ë¹„ê²¼" in game_result or "ì¸ì‹í•˜ì§€ ëª»í–ˆì–´ìš”" in game_result:
                            self.tts.speak("ë‹¤ì‹œ í•œ ë²ˆ í• ê²Œìš”!")
                            time.sleep(2)
                            continue 
                        else:
                            self.tts.speak("ë˜ í•˜ê³  ì‹¶ìœ¼ì‹œë©´ 'ê°€ìœ„ë°”ìœ„ë³´'ë¼ê³  ë§í•´ì£¼ì„¸ìš”.")
                            break
                finally:
                    self.lower_busy_signal()
                
                    model_text = f"ê²Œì„ ì¢…ë£Œ. ìµœì¢… ê²°ê³¼: {final_game_result}"
                    if self.emotion_queue: self.emotion_queue.put("NEUTRAL")
            
            print(f"[{ts}] [Gemini] {model_text}\n")
            if speak_text: self.tts.speak(speak_text)
            
        except Exception as e: print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}\n")

    def _on_press(self, key):
        if self.stop_event.is_set(): return False
        try:
            if key == keyboard.Key.space: self._start_recording()
        except Exception as e: print(f"[í‚¤ ì²˜ë¦¬ ì˜¤ë¥˜ on_press] {e}", file=sys.stderr)

    def _on_release(self, key):
        if self.stop_event.is_set(): return False
        try:
            if key == keyboard.Key.space:
                self.last_activity_time = time.time()
                self._stop_recording_and_transcribe()
            elif key == keyboard.Key.esc:
                print("ESC ê°ì§€ -> ì¢…ë£Œ ì‹ í˜¸ ë³´ëƒ„")
                if self.current_listener and self.current_listener.is_alive():
                    self.current_listener.stop()
                self.stop_event.set()
                return False 
        except Exception as e: print(f"[í‚¤ ì²˜ë¦¬ ì˜¤ë¥˜ on_release] {e}", file=sys.stderr)

    def run(self):
        print("â–¶ ì´ˆê¸° ëŒ€í™” ì„¸ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤. (40ì´ˆ í›„ ë¹„í™œì„±í™”)")
        self.last_activity_time = time.time()
        self.current_listener = keyboard.Listener(on_press=self._on_press, on_release=self._on_release)
        self.current_listener.start()
        
        while not self.stop_event.is_set() and ((self.busy_signals > 0) or (time.time() - self.last_activity_time < 40)):
            time.sleep(0.1)

        if self.current_listener.is_alive():
            self.current_listener.stop()
            self.current_listener = None 

        if not self.stop_event.is_set():
            print("â–¶ ì´ˆê¸° ëŒ€í™” ì„¸ì…˜ ì‹œê°„ ì´ˆê³¼. ì´ì œ í•«ì›Œë“œ ëŒ€ê¸° ìƒíƒœë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            if self.emotion_queue:
                self.emotion_queue.put("SLEEPY")

        while not self.stop_event.is_set():
            print("â–¶ 'ì•ˆë…• ëª¨í‹°' í˜¸ì¶œ(SLEEPY ìƒíƒœì—ì„œ)ì„ ê¸°ë‹¤ë¦½ë‹ˆë‹¤... (ì¢…ë£Œ: ESC)")
            try:
                signal = self.hotword_queue.get(timeout=1.0)
                
                if signal == "hotword_detected" and not self.stop_event.is_set():
                    print("ğŸ’¡ í•«ì›Œë“œ ê°ì§€! ëŒ€í™” ì„¸ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                    if self.emotion_queue: self.emotion_queue.put("WAKE")
                    self.tts.speak("ë„¤, ë§ì”€í•˜ì„¸ìš”.")
                    
                    self.last_activity_time = time.time()
                    self.current_listener = keyboard.Listener(on_press=self._on_press, on_release=self._on_release)
                    self.current_listener.start()
                    
                    while (self.busy_signals > 0) or (time.time() - self.last_activity_time < 40):
                        if self.stop_event.is_set(): break
                        time.sleep(0.1)

                    if self.current_listener.is_alive():
                        self.current_listener.stop()
                    
                    if not self.stop_event.is_set():
                            print("â–¶ ëŒ€í™” ì„¸ì…˜ ì‹œê°„ ì´ˆê³¼. ë‹¤ì‹œ í•«ì›Œë“œ ëŒ€ê¸° ìƒíƒœë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                            if self.emotion_queue:
                                self.emotion_queue.put("SLEEPY")
            except queue.Empty:
                continue
            except (KeyboardInterrupt, SystemExit):
                self.stop_event.set()
                break
        
        print("PTT App ì¢…ë£Œ ì ˆì°¨ ì‹œì‘...")
        if self.current_listener and self.current_listener.is_alive():
            self.current_listener.stop()
        try:
            if FAREWELL_TEXT: self.tts.speak(FAREWELL_TEXT)
        finally:
            self.tts.close_and_join(drain=True)
        print("PTT App ì •ìƒ ì¢…ë£Œ")
        
    def _snoring_worker(self):
        """sleepy_eventê°€ ì¼œì ¸ ìˆëŠ” ë™ì•ˆ ì£¼ê¸°ì ìœ¼ë¡œ ì½”ë¥¼ ê³ ëŠ” ì›Œì»¤"""
        print("â–¶ ì½”ê³¨ì´ ìŠ¤ë ˆë“œ ì‹œì‘ë¨ (í˜„ì¬ ëŒ€ê¸° ì¤‘).")
        snore_options = {
            "text": "ë“œë¥´ë ... ì¿ ìš°...",
            "rate": -10,
            "volume": 20
        }
        SNORE_INTERVAL = 8

        while not self.stop_event.is_set():
            self.sleepy_event.wait() 

            while self.sleepy_event.is_set() and not self.stop_event.is_set():
                self.tts.speak(snore_options)
                
                for _ in range(SNORE_INTERVAL * 2):
                    if not self.sleepy_event.is_set() or self.stop_event.is_set():
                        break
                    time.sleep(0.5)
        print("â–  ì½”ê³¨ì´ ìŠ¤ë ˆë“œ ì¢…ë£Œ.")